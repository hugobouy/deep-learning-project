% CVPR 2022 Paper Template
% based on the CVPR template provided by Ming-Ming Cheng (https://github.com/MCG-NKU/CVPR_Template)
% modified and extended by Stefan Roth (stefan.roth@NOSPAMtu-darmstadt.de)

\documentclass[10pt,twocolumn,letterpaper]{article}

%%%%%%%%% PAPER TYPE  - PLEASE UPDATE FOR FINAL VERSION
%\usepackage[review]{cvpr}      % To produce the REVIEW version
\usepackage{cvpr}              % To produce the CAMERA-READY version
%\usepackage[pagenumbers]{cvpr} % To force page numbers, e.g. for an arXiv version

% Include other packages here, before hyperref.
\usepackage{graphicx}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{booktabs}


% It is strongly recommended to use hyperref, especially for the review version.
% hyperref with option pagebackref eases the reviewers' job.
% Please disable hyperref *only* if you encounter grave issues, e.g. with the
% file validation for the camera-ready version.
%
% If you comment hyperref and then uncomment it, you should delete
% ReviewTempalte.aux before re-running LaTeX.
% (Or just hit 'q' on the first LaTeX run, let it finish, and you
%  should be clear).
\usepackage[pagebackref,breaklinks,colorlinks]{hyperref}


% Support for easy cross-referencing
\usepackage[capitalize]{cleveref}
\crefname{section}{Sec.}{Secs.}
\Crefname{section}{Section}{Sections}
\Crefname{table}{Table}{Tables}
\crefname{table}{Tab.}{Tabs.}


%%%%%%%%% PAPER ID  - PLEASE UPDATE
\def\cvprPaperID{****} % *** Enter the CVPR Paper ID here
\def\confName{CVPR}
\def\confYear{2023}

\begin{document}

%%%%%%%%% TITLE - PLEASE UPDATE
\title{Project proposal: Unmasking Sarcasm - Enhancing Sentiment Analysis in E-Commerce Reviews and Questions
}

\author{Hugo Bouy\\
Illinois Tech\\
{\tt\small hbouy@hawk.iit.edu}
% For a paper whose authors are all at the same institution,
% omit the following lines up until the closing ``}''.
% Additional authors and addresses can be added with ``\and'',
% just like the second author.
% To save space, use either the email address or home page, not both
\and
Rémi Kalbe\\
Illinois Tech\\
{\tt\small rkalbe@hawk.iit.edu}
\and
Mathias Roumane\\
Illinois Tech\\
{\tt\small mroumane@hawk.iit.edu}
}
\maketitle

%%%%%%%%% ABSTRACT
% \begin{abstract}
%    The ABSTRACT is to be in fully justified italicized text, at the top of the left-hand column, below the author and affiliation information.
%    Use the word ``Abstract'' as the title, in 12-point Times, boldface type, centered relative to the column, initially capitalized.
%    The abstract is to be in 10-point, single-spaced type.
%    Leave two blank lines after the Abstract, then begin the main text.
%    Look at previous CVPR abstracts to get a feel for style and length.
% \end{abstract}

%%%%%%%%% BODY TEXT
\section{Problem description}
\label{sec:intro}
Online reviews and questions on e-commerce platforms like Amazon play a critical role in guiding consumer purchasing decisions. However, sarcasm and humor in reviews and questions can mislead sentiment analysis tools, affecting both sellers and buyers. Our project aims to develop a machine learning model to detect sarcasm and humor in Amazon reviews and questions, ensuring a more accurate representation of consumer sentiment.

%-------------------------------------------------------------------------
\section{Brief Survey of Previous Work}

In the work by Poria et al.~\cite{poria2020}, the authors present a sarcasm detection method using deep convolutional neural networks (CNNs). They argue that traditional approaches, which treat sarcasm detection as text categorization, often miss the deeper understanding of language nuances required for sarcasm. Their method integrates sentiment, emotion, and personality features extracted from pre-trained CNNs. By leveraging Twitter data, they contrast sarcastic sentences with the ground-truth polarity of events, and their experiments with word embeddings from word2vec and a combined CNN-SVM scheme showed superior performance on benchmark datasets.

Jain et al.~\cite{jain2019} explored the complexities of identifying sarcasm in Amazon reviews. Recognizing sarcasm is crucial for accurate sentiment analysis, especially since sarcastic comments can be misinterpreted by traditional opinion mining methods. They utilized the "Sarcasm Corpus" containing labeled ironic and regular Amazon reviews, extracting features like sentiment scores, punctuation patterns, and contextual elements that consider the contrast between review sentiment and product rating. Their experiments showed the Support Vector Machine (SVM) classifier as the most accurate, emphasizing the role of context in sarcasm detection.

Yaghoobian et al.~\cite{yaghoobian2020} discussed the challenges of sarcasm detection in sentiment analysis. They identified shifts in sarcasm detection methodologies and categorized detection methods into content-based, which focus on lexical indicators, and context-based, which emphasize background knowledge. Their study highlighted the CASCADE model, which uses user embeddings to capture user-specific features, as an example of leveraging context for sarcasm detection.

Ziser et al.~\cite{ziser2020} demonstrated product bias in Product Question Answering (PQA) systems, where certain products attract more humorous questions. They proposed a deep-learning framework to detect humor in PQA, focusing on incongruity and subjectivity.

Annamoradnejad and Zoghi~\cite{annamoradnejad2020} proposed a humor detection model named ColBERT, which uses BERT embeddings for sentence representation, achieving state-of-the-art results on various datasets.

Gupta et al.~\cite{gupta2021} explored the use of Large Language Models (LLMs) in humor detection, emphasizing their capability to capture the intricacies associated with humor and offense detection.

%-------------------------------------------------------------------------

\section{Preliminary Plan and Ideas}

Our project focus on how sentiment analysis tools dedicated to sarcasm and humor disambiguation can be used to enhance E-commerce review and Q\&A processing.
It can be divided in 5 main milestones:

\begin{enumerate}
    \item First, we implement a basic model able to detect humor/sarcasm in small text reviews. This model would only be capable of saying whether or not a given phrase/text contains humor or sarcasm patterns. To build the model, we compare different approaches published in the scientific literature.
    
    \item Second, we improve the model to take into account several factors such as the type of product considered, its description, price, etc. (as sarcasm may be related to one aspect of the product). Feeding the model with the context can also help identify if some type of products are more prone to trigger humorous or sarcastic comments.
    
    \item Third, we compare our model to a LLM such as ChatGPT to assess if our dedicated humor/sarcasm classification model performs significantly better than a state of the art LLM using an appropriate prompt. We analyze the cost of both solutions.
    
    \item Forth, we improve our model to properly classify a product review considering its sarcastic/humorous sense into meaningful categories such as "consumer thinks the product is overpriced", "consumer thinks the product is good quality", etc. For instance, humor regarding the price of a product may indicate the product is overpriced compared to the customer’s expectations.
    
    \item If time allows it, we use our sarcastic model detection to improve automatic answer generation to take into account the humorous tone of the comment / question.
\end{enumerate}

%%%%%%%%% REFERENCES
{\small
\bibliographystyle{ieee_fullname}
\bibliography{egbib}
}

\end{document}
