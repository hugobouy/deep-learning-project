{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from Sarcasm Amazon Review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, data_folder_path, transform=None):\n",
    "        self.data_folder_path = data_folder_path\n",
    "        self.transform = transform\n",
    "\n",
    "        self.data_list = list()\n",
    "        self.data_list.extend([os.path.join(\"Ironic\", file) for file in os.listdir(os.path.join(dataset_path, \"Ironic\")) if file.endswith(\".txt\")])\n",
    "        self.data_list.extend([os.path.join(\"Regular\", file) for file in os.listdir(os.path.join(dataset_path, \"Regular\")) if file.endswith(\".txt\")])\n",
    "\n",
    "    def __len__(self):\n",
    "        # Return the total number of samples in your dataset\n",
    "        return len(self.data_list)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Load and process the text file at the given index and return it\n",
    "        os.chdir(self.data_folder_path)\n",
    "        file_path = self.data_list[idx]\n",
    "\n",
    "        # Get the label from the file name\n",
    "        label = 0 if 'Regular' in file_path else 1\n",
    "\n",
    "        text_data = None\n",
    "        # Read the review\n",
    "        with open(file_path, 'r', encoding=\"unicode_escape\") as file:\n",
    "            # First line is the number of stars of the review\n",
    "            first_line = file.readline()\n",
    "            # ï»¿ is the BOM character\n",
    "            first_line = first_line.replace('ï»¿', '').replace('<STARS>', '').replace('</STARS>\\n', '')\n",
    "            stars = float(first_line)\n",
    "\n",
    "            # Then fin the <REVIEW> tag to retrive the review text\n",
    "            for line in file:\n",
    "                if '<REVIEW>' in line:\n",
    "                        text_data = file.readlines()\n",
    "\n",
    "        # Remove \\n and combine in one string\n",
    "        text_data = ' '.join([line.replace('\\n', '') for line in text_data])\n",
    "        # Remove </REVIEW> and &quot; tokens\n",
    "        text_data = text_data.replace('</REVIEW>', '').replace('&quot;', '')\n",
    "        \n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            text_data = self.transform(text_data)\n",
    "        \n",
    "        # Return the processed data and its corresponding label (if applicable)\n",
    "        return text_data, label, stars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1003 125 126\n",
      "639 364\n"
     ]
    }
   ],
   "source": [
    "os.chdir(\"../../datasets/SarcasmAmazonReviewsCorpus-master\")\n",
    "dataset_path = os.path.abspath(os.curdir)\n",
    "dataset = CustomDataset(dataset_path)\n",
    "\n",
    "# Suffle the dataset\n",
    "torch.manual_seed(0)\n",
    "indices = torch.randperm(len(dataset)).tolist()\n",
    "dataset = torch.utils.data.Subset(dataset, indices)\n",
    "\n",
    "# Split the dataset into train, validation and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset, val_dataset, test_dataset = torch.utils.data.random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "# Set sizes\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
    "\n",
    "# Labels rates (0: Regular, 1: Ironic)\n",
    "labels = [label for _, label, _ in train_dataset]\n",
    "print(labels.count(0), labels.count(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"The Sun also Rises made a huge impression on me when I read it as a college student a number of years ago.  It is true that one must look beyond the surface to get a clear understanding of any book by Hemingway.   It is also true that the language that he used was not flowery, nor overly  eloquent but the meaning revealed within the lines.  It is also true that  the characters are often expatriates; living on the fringe of society and  hedonistic to the max.  All of those elements are visible here, yet  sometimes it might require a magnifying glass to see it.  However, these  are the qualities which make Ernest Hemingway, the seminal writer for a  generation and certainly one of the best.      I propose one hint when  reading the Sun also Rises.  Pay close attention to the  relationship between Barnes and Robert Cohn.  Barnes laothes Cohn for being  everything that he is not.  What drives him over the edge (in the inner  sanctum of his own mind and demons) is the success Cohn has insofar as his  relationship with Lady Brett.  Barnes is impotent and this is a crushing  blow to his manhood.  The tragedy here is his inability to consummate a  sexual relationship with her.  It destroys him--yet he is still accepting  of his predicament.  This is what allows this character to maintain  grace under pressure-- as Hemingway once coined the  term or  the ability to stand or hold ones ground when all odds are against you.   Certainly this can be a tragic flaw for any of Hemingway's male  characters--the total loss of his virility.  Yet he stands his ground and  never loses it.  He just hates Cohn from a distance and rationalizes that  he (Cohn) is one who cannot do anything just for the sake of doing  it---whether it be drinking, winning the Princeton boxing title, or being  in love with Brett.  It is complicated but one can come away with these  qualities after finishing the novel rather than while reading it.      I  think his friend and sometimes rival, F. Scott Fitzgerald, summed him up  best when he said of Hemingway: He's the real thing. \", 5.0]\n"
     ]
    }
   ],
   "source": [
    "# Retrive the data and labels from the dataset into numpy array\n",
    "train_data = list()\n",
    "train_labels = list()\n",
    "for data, label, stars in train_dataset:\n",
    "    train_data.append([data, stars])\n",
    "    train_labels.append(label)\n",
    "\n",
    "val_data = list()\n",
    "val_labels = list()\n",
    "for data, label, stars in val_dataset:\n",
    "    val_data.append([data, stars])\n",
    "    val_labels.append(label)\n",
    "\n",
    "test_data = list()\n",
    "test_labels = list()\n",
    "for data, label, stars in test_dataset:\n",
    "    test_data.append([data, stars])\n",
    "    test_labels.append(label)\n",
    "\n",
    "print(train_data[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features building functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import stanza"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score_feature(text, analyzer):\n",
    "    \"\"\"!\n",
    "    @brief Get the sentiment score feature of a text using VADER sentiment analysis tool.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @param analyzer (SentimentIntensityAnalyzer): VADER sentiment analysis tool.\n",
    "    @return (dict): Sentiment score feature of the text.\n",
    "    \"\"\"\n",
    "    return analyzer.polarity_scores(text)[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punctuation_feature(text):\n",
    "    \"\"\"!\n",
    "    @brief Get the punctuation feature of a text.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @return (list): List of punctuation counts normalized by the total count of punctuation in the text.\n",
    "                    [count of '.', count of '!', count of '?', count of ',']\n",
    "    \"\"\"\n",
    "    punctuations = ['.', '!', '?', ',']\n",
    "    punctuations_counts = list()\n",
    "    total_count = 0\n",
    "    for punctuation in punctuations:\n",
    "        count = text.count(punctuation)\n",
    "        punctuations_counts.append(count)\n",
    "        total_count += count\n",
    "    # Normalize the counts (ratio of punctuation count to total count)\n",
    "    if total_count != 0:\n",
    "        punctuations_counts = [count / total_count for count in punctuations_counts]\n",
    "    return punctuations_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_POS_feature(text, pipeline):\n",
    "    \"\"\"!\n",
    "    @brief Get the POS feature of a text.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @param pipeline (stanza.Pipeline): The Stanza pipeline use for the constituency parsing.\n",
    "    @return (list): List of POS tag counts normalized by the total count of POS tags in the text.\n",
    "                    [Noun count, Verb count, Adjective count, Adverb count]\n",
    "    \"\"\"\n",
    "    doc = pipeline(text)\n",
    "    POS_tags = ['NOUN', 'VERB', 'ADJ', 'ADV']\n",
    "    POS_counts = [0, 0, 0, 0]\n",
    "    total_count = 0\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            total_count += 1\n",
    "            if word.upos in POS_tags:\n",
    "                POS_counts[POS_tags.index(word.upos)] += 1\n",
    "    # Normalize the counts (ratio of POS tag count to total count)\n",
    "    if total_count != 0:\n",
    "        POS_counts = [count / total_count for count in POS_counts]\n",
    "\n",
    "    return POS_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_unigram_bigram_feature(text, vocabulary_sarcastic, vocabulary_regular, top_range):\n",
    "    \"\"\"!\n",
    "    @brief Get the word unigram and bigram feature of a text.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @param vocabulary_sarcastic (dict): Vocabulary of sarcastic words.\n",
    "    @param vocabulary_regular (dict): Vocabulary of regular words.\n",
    "    @param top_range (int): Number of top words to be considered for the feature.\n",
    "    @return (list): List of word unigram and bigram counts normalized by the total count of words in the text.\n",
    "                    [count of sarcastic words, count of regular words, count of sarcastic bigrams, count of regular bigrams]\n",
    "    \"\"\"\n",
    "    # Only consider the top words of the vocabulary\n",
    "    vocabulary_sarcastic = dict(sorted(vocabulary_sarcastic.items(), key=lambda item: item[1], reverse=True)[:top_range])\n",
    "    vocabulary_regular = dict(sorted(vocabulary_regular.items(), key=lambda item: item[1], reverse=True)[:top_range])\n",
    "    # Get the word unigram and bigram counts\n",
    "    word_unigram_bigram_counts = [0, 0, 0, 0]\n",
    "    word_unigram_bigram_counts[0] = sum([text.count(word) for word in vocabulary_sarcastic.keys()])\n",
    "    word_unigram_bigram_counts[1] = sum([text.count(word) for word in vocabulary_regular.keys()])\n",
    "    word_unigram_bigram_counts[2] = sum([text.count(word) for word in vocabulary_sarcastic.keys() if len(word.split()) == 2])\n",
    "    word_unigram_bigram_counts[3] = sum([text.count(word) for word in vocabulary_regular.keys() if len(word.split()) == 2])\n",
    "    # Normalize the counts (ratio of word unigram and bigram count to total count)\n",
    "    total_count = sum(word_unigram_bigram_counts)\n",
    "    if total_count != 0:\n",
    "        word_unigram_bigram_counts = [count / total_count for count in word_unigram_bigram_counts]\n",
    "    return word_unigram_bigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contextual_feature(text, sentiment_score, review_stars):\n",
    "    \"\"\"!\n",
    "    @brief Get the contextual feature of a text.\n",
    "    A sarcastic text may have a sentiment score that contradicts the review stars.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @param sentiment_score (float): Sentiment score of the text.\n",
    "    @param review_stars (float): Review stars of the text.\n",
    "    @return (float): Absolute difference between the sentiment score (normalized) and review stars.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize sentiment_score on a 0 to 5 scale (scale of review_stars)\n",
    "    # Sentiment score is in the range [-1, 1]\n",
    "    sentiment_score = (sentiment_score + 1) * 2.5\n",
    "    diff = abs(sentiment_score - review_stars)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(text, review_starts, vocabulary_sarcastic, vocabulary_regular, analyzer, constituency_parser):\n",
    "    \"\"\"!\n",
    "    @brief Get the feature vector of a text.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @param review_starts (float): Review stars of the text.\n",
    "    @param vocabulary_sarcastic (dict): Vocabulary of sarcastic set.\n",
    "    @param vocabulary_regular (dict): Vocabulary of regular set.\n",
    "    @param analyzer (SentimentIntensityAnalyzer): VADER sentiment analysis tool.\n",
    "    @param constituency_parser (stanza.Pipeline): The Stanza pipeline use for the constituency parsing.\n",
    "    @return (list): Feature vector of the text.\n",
    "    \"\"\"\n",
    "    # Get features\n",
    "    sentiment_score = get_sentiment_score_feature(text, analyzer)\n",
    "    punctuation_counts = get_punctuation_feature(text)\n",
    "    POS_counts = get_POS_feature(text, constituency_parser)\n",
    "    word_unigram_bigram_counts = get_word_unigram_bigram_feature(text, vocabulary_sarcastic, vocabulary_regular, 100)\n",
    "    contextual_feature = get_contextual_feature(text, sentiment_score, review_starts)\n",
    "\n",
    "    # Concatenate features in a single vector\n",
    "    feature_vector = [sentiment_score]\n",
    "    feature_vector.extend(punctuation_counts)\n",
    "    feature_vector.extend(POS_counts)\n",
    "    feature_vector.extend(word_unigram_bigram_counts)\n",
    "    feature_vector.append(contextual_feature)\n",
    "\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabularies_from_dataset(data, labels, vectorizer):\n",
    "    \"\"\"!\n",
    "    @brief Get the vocabulary of sarcastic and regular texts from the dataset.\n",
    "    @param data (list): List of texts.\n",
    "    @param labels (list): List of labels.\n",
    "    @param vectorizer (CountVectorizer): CountVectorizer object.\n",
    "    @return (tuple): Vocabulary of sarcastic texts, vocabulary of regular texts.\n",
    "    \"\"\"\n",
    "    sarcastic_sentences = list()\n",
    "    regular_sentences = list()\n",
    "    for i in range(len(data)):\n",
    "        if labels[i] == 0:\n",
    "            regular_sentences.append(data[i][0])\n",
    "        else:\n",
    "            sarcastic_sentences.append(data[i][0])\n",
    "    vectorizer.fit(sarcastic_sentences)\n",
    "    vocabulary_sarcastic = vectorizer.vocabulary_\n",
    "    vectorizer.fit(regular_sentences)\n",
    "    vocabulary_regular = vectorizer.vocabulary_\n",
    "    return vocabulary_sarcastic, vocabulary_regular\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 11:14:13 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: 367kB [00:00, 18.7MB/s]                    \n",
      "2023-12-01 11:14:13 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2023-12-01 11:14:13 INFO: Using device: cpu\n",
      "2023-12-01 11:14:13 INFO: Loading: tokenize\n",
      "2023-12-01 11:14:13 INFO: Loading: pos\n",
      "2023-12-01 11:14:13 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "constituency_parser = stanza.Pipeline(lang='en', processors='tokenize,pos')\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2), max_features=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_sarcastic, vocabulary_regular = get_vocabularies_from_dataset(train_data, train_labels, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1003/1003 [10:19<00:00,  1.62it/s]\n",
      "100%|██████████| 125/125 [01:14<00:00,  1.67it/s]\n",
      "100%|██████████| 126/126 [01:24<00:00,  1.49it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_vectors_train = list()\n",
    "feature_vectors_val = list()\n",
    "feature_vectors_test = list()\n",
    "for i in tqdm(range(len(train_data))):\n",
    "    feature_vectors_train.append(get_feature_vector(train_data[i][0], train_data[i][1], vocabulary_sarcastic, vocabulary_regular, analyzer, constituency_parser))\n",
    "for i in tqdm(range(len(val_data))):\n",
    "    feature_vectors_val.append(get_feature_vector(val_data[i][0], val_data[i][1], vocabulary_sarcastic, vocabulary_regular, analyzer, constituency_parser))\n",
    "for i in tqdm(range(len(test_data))):\n",
    "    feature_vectors_test.append(get_feature_vector(test_data[i][0], test_data[i][1], vocabulary_sarcastic, vocabulary_regular, analyzer, constituency_parser))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9825, 0.7142857142857143, 0.0, 0.0, 0.2857142857142857, 0.14640198511166252, 0.10421836228287841, 0.05707196029776675, 0.062034739454094295, 0.54, 0.46, 0.0, 0.0, 0.04375000000000018]\n"
     ]
    }
   ],
   "source": [
    "print(feature_vectors_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature vectors to numpy files\n",
    "np.save('feature_vectors_train.npy', feature_vectors_train)\n",
    "np.save('feature_vectors_val.npy', feature_vectors_val)\n",
    "np.save('feature_vectors_test.npy', feature_vectors_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from numpy files\n",
    "feature_vectors_train_read = np.load('feature_vectors_train.npy')\n",
    "feature_vectors_val_read = np.load('feature_vectors_val.npy')\n",
    "feature_vectors_test_read = np.load('feature_vectors_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.78      0.82        87\n",
      "           1       0.60      0.74      0.66        38\n",
      "\n",
      "    accuracy                           0.77       125\n",
      "   macro avg       0.73      0.76      0.74       125\n",
      "weighted avg       0.79      0.77      0.77       125\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.86      0.86        91\n",
      "           1       0.64      0.66      0.65        35\n",
      "\n",
      "    accuracy                           0.80       126\n",
      "   macro avg       0.75      0.76      0.75       126\n",
      "weighted avg       0.80      0.80      0.80       126\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(feature_vectors_train_read, train_labels)\n",
    "\n",
    "y_pred = clf.predict(feature_vectors_val_read)\n",
    "print(classification_report(val_labels, y_pred))\n",
    "\n",
    "y_pred = clf.predict(feature_vectors_test_read)\n",
    "print(classification_report(test_labels, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
