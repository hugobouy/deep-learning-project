{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read data from Sarcasm Amazon Review dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>product</th>\n",
       "      <th>review</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Listening to this \"Hurt\" me!</td>\n",
       "      <td>November 8, 2007</td>\n",
       "      <td>MomKKC \"momkkc\"</td>\n",
       "      <td>The Sun Also Rises (Audio CD)</td>\n",
       "      <td>William Hurt cannot read.  At all.  The cadenc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40% price hike, hmm</td>\n",
       "      <td>April 15, 2010</td>\n",
       "      <td>M. Barnhart</td>\n",
       "      <td>Heineken BT06 BeerTender Tubes, Pack of 6 (Kit...</td>\n",
       "      <td>As another reviewer noted, these used to be 10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Don't Mess With the Lupine Trinity!!!</td>\n",
       "      <td>June 2, 2010</td>\n",
       "      <td>Jake &amp;#34;The Wolfman&amp;#34; Sanchez</td>\n",
       "      <td>The Mountain Three Wolf Moon Short Sleeve Tee ...</td>\n",
       "      <td>I've read several reviews from people who have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>IT'S A BLENDER!</td>\n",
       "      <td>June 17, 2010</td>\n",
       "      <td>S. Cashdollar</td>\n",
       "      <td>Margaritaville DM1000 Frozen Concoction Maker ...</td>\n",
       "      <td>If you pay $250 for this blender you need your...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Another movie to ignore....</td>\n",
       "      <td>April 24, 2010</td>\n",
       "      <td>Kody \"ParisHiltonFan\"</td>\n",
       "      <td>Valentine's Day (DVD)</td>\n",
       "      <td>A perfect date movie: you'll miss absolutely n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                  title              date  \\\n",
       "0    1.0           Listening to this \"Hurt\" me!  November 8, 2007   \n",
       "1    1.0                    40% price hike, hmm    April 15, 2010   \n",
       "2    5.0  Don't Mess With the Lupine Trinity!!!      June 2, 2010   \n",
       "3    1.0                        IT'S A BLENDER!     June 17, 2010   \n",
       "4    1.0            Another movie to ignore....    April 24, 2010   \n",
       "\n",
       "                               author  \\\n",
       "0                     MomKKC \"momkkc\"   \n",
       "1                         M. Barnhart   \n",
       "2  Jake &#34;The Wolfman&#34; Sanchez   \n",
       "3                       S. Cashdollar   \n",
       "4               Kody \"ParisHiltonFan\"   \n",
       "\n",
       "                                             product  \\\n",
       "0                      The Sun Also Rises (Audio CD)   \n",
       "1  Heineken BT06 BeerTender Tubes, Pack of 6 (Kit...   \n",
       "2  The Mountain Three Wolf Moon Short Sleeve Tee ...   \n",
       "3  Margaritaville DM1000 Frozen Concoction Maker ...   \n",
       "4                              Valentine's Day (DVD)   \n",
       "\n",
       "                                              review  is_sarcastic  \n",
       "0  William Hurt cannot read.  At all.  The cadenc...             1  \n",
       "1  As another reviewer noted, these used to be 10...             1  \n",
       "2  I've read several reviews from people who have...             1  \n",
       "3  If you pay $250 for this blender you need your...             1  \n",
       "4  A perfect date movie: you'll miss absolutely n...             1  "
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "amazon_dataset_path = os.path.join('..', '..', 'datasets', 'amazon_combined.csv')\n",
    "dataset = pd.read_csv(amazon_dataset_path)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>product</th>\n",
       "      <th>review</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Meyers' books are GREAT....</td>\n",
       "      <td>April 4, 2008</td>\n",
       "      <td>Smarmstress</td>\n",
       "      <td>New Moon (The Twilight Saga, Book 2) (Hardcover)</td>\n",
       "      <td>...if you're an aspiring writer in need of a p...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "      <td>The correct 5-quart bowl numbers</td>\n",
       "      <td>January 2, 2007</td>\n",
       "      <td>Steven Quigley</td>\n",
       "      <td>KitchenAid K5ASBP Bowl for 5-Quart Professiona...</td>\n",
       "      <td>If you do a lot of cooking or baking, an extra...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Please.  Everyone.  Stop!  Please stop wearing...</td>\n",
       "      <td>May 26, 2009</td>\n",
       "      <td>The Wild Gunman \"man on the run\"</td>\n",
       "      <td>crocs Classic Sandal (3.5\" and 5.25\" disks)</td>\n",
       "      <td>Let's get one thing straight.  These things ar...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Sansa m250 Promises but fails to deliver</td>\n",
       "      <td>June 16, 2008</td>\n",
       "      <td>Hemanth Kumar</td>\n",
       "      <td>SanDisk Sansa m250 2 GB MP3 Player (Black) (El...</td>\n",
       "      <td>I bought it and it worked right for some time....</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "      <td>What can I say - it's Bacon!</td>\n",
       "      <td>February 24, 2009</td>\n",
       "      <td>W. D. Hairston \"Huh? What?\"</td>\n",
       "      <td>Bacon Bandaid Bandages (Toy)</td>\n",
       "      <td>What can one possibly say that isn't self expl...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   stars                                              title  \\\n",
       "0    1.0                        Meyers' books are GREAT....   \n",
       "1    5.0                   The correct 5-quart bowl numbers   \n",
       "2    1.0  Please.  Everyone.  Stop!  Please stop wearing...   \n",
       "3    1.0           Sansa m250 Promises but fails to deliver   \n",
       "4    4.0                       What can I say - it's Bacon!   \n",
       "\n",
       "                date                            author  \\\n",
       "0      April 4, 2008                       Smarmstress   \n",
       "1    January 2, 2007                    Steven Quigley   \n",
       "2       May 26, 2009  The Wild Gunman \"man on the run\"   \n",
       "3      June 16, 2008                     Hemanth Kumar   \n",
       "4  February 24, 2009       W. D. Hairston \"Huh? What?\"   \n",
       "\n",
       "                                             product  \\\n",
       "0   New Moon (The Twilight Saga, Book 2) (Hardcover)   \n",
       "1  KitchenAid K5ASBP Bowl for 5-Quart Professiona...   \n",
       "2        crocs Classic Sandal (3.5\" and 5.25\" disks)   \n",
       "3  SanDisk Sansa m250 2 GB MP3 Player (Black) (El...   \n",
       "4                       Bacon Bandaid Bandages (Toy)   \n",
       "\n",
       "                                              review  is_sarcastic  \n",
       "0  ...if you're an aspiring writer in need of a p...             1  \n",
       "1  If you do a lot of cooking or baking, an extra...             0  \n",
       "2  Let's get one thing straight.  These things ar...             1  \n",
       "3  I bought it and it worked right for some time....             0  \n",
       "4  What can one possibly say that isn't self expl...             1  "
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Suffle the dataset (random_state=1 for reproducibility)\n",
    "dataset = dataset.sample(frac=1, random_state=1).reset_index(drop=True)\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subsets sizes:\n",
      "1003 125 126\n",
      "Labels rates:\n",
      "is_sarcastic\n",
      "0    643\n",
      "1    360\n",
      "Name: count, dtype: int64\n",
      "is_sarcastic\n",
      "0    84\n",
      "1    41\n",
      "Name: count, dtype: int64\n",
      "is_sarcastic\n",
      "0    90\n",
      "1    36\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Split the dataset into train, validation and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size\n",
    "\n",
    "train_dataset = dataset[:train_size]\n",
    "val_dataset = dataset[train_size:train_size+val_size].reset_index(drop=True)\n",
    "test_dataset = dataset[train_size+val_size:].reset_index(drop=True)\n",
    "\n",
    "# Sizes of the sub-datasets\n",
    "print(\"Subsets sizes:\")\n",
    "print(len(train_dataset), len(val_dataset), len(test_dataset))\n",
    "val_dataset.head()\n",
    "\n",
    "#Labels rates (0: Regular, 1: Ironic)\n",
    "print(\"Labels rates:\")\n",
    "print(train_dataset['is_sarcastic'].value_counts())\n",
    "print(val_dataset['is_sarcastic'].value_counts())\n",
    "print(test_dataset['is_sarcastic'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Features building functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import stanza\n",
    "import spacy\n",
    "from tqdm import tqdm\n",
    "from nltk import word_tokenize          \n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from rake_nltk import Rake"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_score_feature(text, analyzer):\n",
    "    \"\"\"!\n",
    "    @brief Get the sentiment score feature of a text using VADER sentiment analysis tool.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @param analyzer (SentimentIntensityAnalyzer): VADER sentiment analysis tool.\n",
    "    @return (dict): Sentiment score feature of the text.\n",
    "    \"\"\"\n",
    "    return analyzer.polarity_scores(text)[\"compound\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_punctuation_feature(text):\n",
    "    \"\"\"!\n",
    "    @brief Get the punctuation feature of a text.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @return (list): List of punctuation counts normalized by the total count of punctuation in the text.\n",
    "                    [count of '.', count of '!', count of '?', count of ',']\n",
    "    \"\"\"\n",
    "    punctuations = ['.', '!', '?', ',']\n",
    "    punctuations_counts = list()\n",
    "    total_count = 0\n",
    "    for punctuation in punctuations:\n",
    "        count = text.count(punctuation)\n",
    "        punctuations_counts.append(count)\n",
    "        total_count += count\n",
    "    # Normalize the counts (ratio of punctuation count to total count)\n",
    "    if total_count != 0:\n",
    "        punctuations_counts = [count / total_count for count in punctuations_counts]\n",
    "    return punctuations_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_POS_feature(text, pipeline):\n",
    "    \"\"\"!\n",
    "    @brief Get the POS feature of a text.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @param pipeline (stanza.Pipeline): The Stanza pipeline use for the constituency parsing.\n",
    "    @return (list): List of POS tag counts normalized by the total count of POS tags in the text.\n",
    "                    [Noun count, Verb count, Adjective count, Adverb count]\n",
    "    \"\"\"\n",
    "    doc = pipeline(text)\n",
    "    POS_tags = ['NOUN', 'VERB', 'ADJ', 'ADV']\n",
    "    POS_counts = [0, 0, 0, 0]\n",
    "    total_count = 0\n",
    "    for sentence in doc.sentences:\n",
    "        for word in sentence.words:\n",
    "            total_count += 1\n",
    "            if word.upos in POS_tags:\n",
    "                POS_counts[POS_tags.index(word.upos)] += 1\n",
    "    # Normalize the counts (ratio of POS tag count to total count)\n",
    "    if total_count != 0:\n",
    "        POS_counts = [count / total_count for count in POS_counts]\n",
    "\n",
    "    return POS_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_word_unigram_bigram_feature(text, vocabulary_sarcastic, vocabulary_regular, top_range):\n",
    "    \"\"\"!\n",
    "    @brief Get the word unigram and bigram feature of a text.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @param vocabulary_sarcastic (dict): Vocabulary of sarcastic words.\n",
    "    @param vocabulary_regular (dict): Vocabulary of regular words.\n",
    "    @param top_range (int): Number of top words to be considered for the feature.\n",
    "    @return (list): List of word unigram and bigram counts normalized by the total count of words in the text.\n",
    "                    [count of sarcastic words, count of regular words, count of sarcastic bigrams, count of regular bigrams]\n",
    "    \"\"\"\n",
    "    # Only consider the top words of the vocabulary\n",
    "    vocabulary_sarcastic = dict(sorted(vocabulary_sarcastic.items(), key=lambda item: item[1], reverse=True)[:top_range])\n",
    "    vocabulary_regular = dict(sorted(vocabulary_regular.items(), key=lambda item: item[1], reverse=True)[:top_range])\n",
    "    # Get the word unigram and bigram counts\n",
    "    word_unigram_bigram_counts = [0, 0, 0, 0]\n",
    "    word_unigram_bigram_counts[0] = sum([text.count(word) for word in vocabulary_sarcastic.keys()])\n",
    "    word_unigram_bigram_counts[1] = sum([text.count(word) for word in vocabulary_regular.keys()])\n",
    "    word_unigram_bigram_counts[2] = sum([text.count(word) for word in vocabulary_sarcastic.keys() if len(word.split()) == 2])\n",
    "    word_unigram_bigram_counts[3] = sum([text.count(word) for word in vocabulary_regular.keys() if len(word.split()) == 2])\n",
    "    # Normalize the counts (ratio of word unigram and bigram count to total count)\n",
    "    total_count = sum(word_unigram_bigram_counts)\n",
    "    if total_count != 0:\n",
    "        word_unigram_bigram_counts = [count / total_count for count in word_unigram_bigram_counts]\n",
    "    return word_unigram_bigram_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_contextual_feature(text, sentiment_score, review_stars):\n",
    "    \"\"\"!\n",
    "    @brief Get the contextual feature of a text.\n",
    "    A sarcastic text may have a sentiment score that contradicts the review stars.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @param sentiment_score (float): Sentiment score of the text.\n",
    "    @param review_stars (float): Review stars of the text.\n",
    "    @return (float): Absolute difference between the sentiment score (normalized) and review stars.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Normalize sentiment_score on a 0 to 5 scale (scale of review_stars)\n",
    "    # Sentiment score is in the range [-1, 1]\n",
    "    sentiment_score = (sentiment_score + 1) * 2.5\n",
    "    diff = abs(sentiment_score - review_stars)\n",
    "    return diff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LemmaTokenizer:\n",
    "    def __init__(self):\n",
    "        self.wnl = WordNetLemmatizer()\n",
    "    def __call__(self, doc):\n",
    "        return [self.wnl.lemmatize(t) for t in word_tokenize(doc)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dict_from_keyword_extracted(keyword_extracted):\n",
    "    vectorizer = CountVectorizer(lowercase=True, tokenizer=LemmaTokenizer())\n",
    "    matrix = vectorizer.fit_transform(keyword_extracted)\n",
    "    counts_dict = dict()\n",
    "    i = 0\n",
    "    for word in vectorizer.get_feature_names_out():\n",
    "        counts_dict[word] = matrix.sum(axis=0).tolist()[0][i]\n",
    "        i += 1\n",
    "    counts_dict = dict(sorted(counts_dict.items(), key=lambda item: item[1], reverse=True))\n",
    "    # Remove punctuation\n",
    "    for punctuation in string.punctuation:\n",
    "        if punctuation in counts_dict.keys():\n",
    "            counts_dict.pop(punctuation)\n",
    "    return counts_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_similarity_feature(review, title, similarity_pipeline, keyword_extractor):\n",
    "    \"\"\"!\n",
    "    @brief Get the similarity feature of a review and a title.\n",
    "    @param review (str): Review to be analyzed.\n",
    "    @param title (str): Title to be analyzed.\n",
    "    @param similarity_pipeline (spacy.lang.en.English): The Spacy pipeline use for the similarity analysis.\n",
    "    @param keyword_extractor (Rake): The Rake keyword extractor.\n",
    "    @return (float): Average similarity between the review and the title.\n",
    "    \"\"\"\n",
    "    # Extract keywords from title and review\n",
    "    keyword_extractor.extract_keywords_from_text(title)\n",
    "    dict_title = get_dict_from_keyword_extracted(keyword_extractor.get_ranked_phrases())\n",
    "    keyword_extractor.extract_keywords_from_text(review)\n",
    "    dict_review = get_dict_from_keyword_extracted(keyword_extractor.get_ranked_phrases())\n",
    "    \n",
    "    # Sort keywords by frequency in the review and only keep the top ones (same number as the title)\n",
    "    dict_review = list(sorted(dict_review.items(), key=lambda item: item[1], reverse=True))\n",
    "    dict_review = dict_review[:len(dict_title)]\n",
    "\n",
    "    # Similarities between top keywords in title and review\n",
    "    similarities = list()\n",
    "    for word_title in dict_title.keys():\n",
    "        for word_review in dict_review:\n",
    "                similarities.append(similarity_pipeline(word_title).similarity(similarity_pipeline(word_review[0])))\n",
    "    \n",
    "    average = sum(similarities) / len(similarities)\n",
    "    return average"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Just a little experiment to verify the relevance of this feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1003 [00:00<04:06,  4.07it/s]/var/folders/7r/d3_ly2ln4yn7612_mtn24q0h0000gn/T/ipykernel_87762/458134087.py:24: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  similarities.append(similarity_pipeline(word_title).similarity(similarity_pipeline(word_review[0])))\n",
      "100%|██████████| 1003/1003 [04:44<00:00,  3.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average similarity feature for sarcastic dataset: 0.14598271274568028\n",
      "Average similarity feature for regular dataset: 0.15680566635173698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Get the average similary feature for sarcastic and regular dataset\n",
    "similarity_pipeline = spacy.load(\"en_core_web_lg\")\n",
    "keyword_extractor = Rake()\n",
    "\n",
    "average_similarity_sarcastic = 0\n",
    "average_similarity_regular = 0\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    if train_dataset['is_sarcastic'][i] == 1:\n",
    "        average_similarity_sarcastic += get_similarity_feature(train_dataset['review'][i], train_dataset['product'][i], similarity_pipeline, keyword_extractor)\n",
    "    else:\n",
    "        average_similarity_regular += get_similarity_feature(train_dataset['review'][i], train_dataset['product'][i], similarity_pipeline, keyword_extractor)\n",
    "average_similarity_sarcastic /= len(train_dataset[train_dataset['is_sarcastic'] == 1])\n",
    "average_similarity_regular /= len(train_dataset[train_dataset['is_sarcastic'] == 0])\n",
    "print(\"Average similarity feature for sarcastic dataset:\", average_similarity_sarcastic)\n",
    "print(\"Average similarity feature for regular dataset:\", average_similarity_regular)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_feature_vector(review, vocabulary_sarcastic, vocabulary_regular, analyzer, constituency_parser, keyword_extractor, similarity_pipeline):\n",
    "    \"\"\"!\n",
    "    @brief Get the feature vector of a text.\n",
    "    @param text (str): Text to be analyzed.\n",
    "    @param review_starts (float): Review stars of the text.\n",
    "    @param vocabulary_sarcastic (dict): Vocabulary of sarcastic set.\n",
    "    @param vocabulary_regular (dict): Vocabulary of regular set.\n",
    "    @param analyzer (SentimentIntensityAnalyzer): VADER sentiment analysis tool.\n",
    "    @param constituency_parser (stanza.Pipeline): The Stanza pipeline use for the constituency parsing.\n",
    "    @param keyword_extractor (Rake): The Rake keyword extractor.\n",
    "    @param similarity_pipeline (spacy.lang.en.English): The Spacy pipeline use for the similarity analysis.\n",
    "    @return (list): Feature vector of the text.\n",
    "    [sentiment score, punctuation counts, POS counts, word unigram and bigram counts, contextual feature, similarity feature, review stars]\n",
    "    \"\"\"\n",
    "    # Get features\n",
    "    sentiment_score = get_sentiment_score_feature(review['review'], analyzer)\n",
    "    punctuation_counts = get_punctuation_feature(review['review'])\n",
    "    POS_counts = get_POS_feature(review['review'], constituency_parser)\n",
    "    word_unigram_bigram_counts = get_word_unigram_bigram_feature(review['review'], vocabulary_sarcastic, vocabulary_regular, 1000)\n",
    "    contextual_feature = get_contextual_feature(review['review'], sentiment_score, review['stars'])\n",
    "    similarity_feature = get_similarity_feature(review['review'], review['product'], similarity_pipeline, keyword_extractor)\n",
    "\n",
    "    # Concatenate features in a single vector\n",
    "    feature_vector = [sentiment_score]\n",
    "    feature_vector.extend(punctuation_counts)\n",
    "    feature_vector.extend(POS_counts)\n",
    "    feature_vector.extend(word_unigram_bigram_counts)\n",
    "    feature_vector.append(contextual_feature)\n",
    "    feature_vector.append(similarity_feature)\n",
    "    feature_vector.append(review['stars'])\n",
    "\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_vocabularies_from_dataset(dataset, vectorizer):\n",
    "    \"\"\"!\n",
    "    @brief Get the vocabulary of sarcastic and regular texts from the dataset.\n",
    "    @param data (list): List of texts.\n",
    "    @param labels (list): List of labels.\n",
    "    @param vectorizer (CountVectorizer): CountVectorizer object.\n",
    "    @return (tuple): Vocabulary of sarcastic texts, vocabulary of regular texts.\n",
    "    \"\"\"\n",
    "    sarcastic_sentences = list()\n",
    "    regular_sentences = list()\n",
    "    for i in range(len(dataset)):\n",
    "        if dataset['is_sarcastic'][i] == 1:\n",
    "            sarcastic_sentences.append(dataset['review'][i])\n",
    "        else:\n",
    "            regular_sentences.append(dataset['review'][i])\n",
    "    vectorizer.fit(sarcastic_sentences)\n",
    "    vocabulary_sarcastic = vectorizer.vocabulary_\n",
    "    vectorizer.fit(regular_sentences)\n",
    "    vocabulary_regular = vectorizer.vocabulary_\n",
    "    return vocabulary_sarcastic, vocabulary_regular\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build feature dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-01 17:29:02 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.6.0.json: 367kB [00:00, 46.5MB/s]                    \n",
      "2023-12-01 17:29:03 INFO: Loading these models for language: en (English):\n",
      "===============================\n",
      "| Processor | Package         |\n",
      "-------------------------------\n",
      "| tokenize  | combined        |\n",
      "| pos       | combined_charlm |\n",
      "===============================\n",
      "\n",
      "2023-12-01 17:29:03 INFO: Using device: cpu\n",
      "2023-12-01 17:29:03 INFO: Loading: tokenize\n",
      "2023-12-01 17:29:03 INFO: Loading: pos\n",
      "2023-12-01 17:29:03 INFO: Done loading processors!\n"
     ]
    }
   ],
   "source": [
    "analyzer = SentimentIntensityAnalyzer()\n",
    "constituency_parser = stanza.Pipeline(lang='en', processors='tokenize,pos')\n",
    "vectorizer = CountVectorizer(lowercase=True, stop_words='english', ngram_range=(1, 2))\n",
    "similarity_pipeline = spacy.load(\"en_core_web_lg\")\n",
    "keyword_extractor = Rake()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocabulary_sarcastic, vocabulary_regular = get_vocabularies_from_dataset(train_dataset, vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9995,\n",
       " 0.4,\n",
       " 0.044444444444444446,\n",
       " 0.022222222222222223,\n",
       " 0.5333333333333333,\n",
       " 0.11348464619492657,\n",
       " 0.102803738317757,\n",
       " 0.08945260347129506,\n",
       " 0.06275033377837116,\n",
       " 0.66,\n",
       " 0.26,\n",
       " 0.06,\n",
       " 0.02,\n",
       " 3.9987500000000002,\n",
       " 0.07309403448939084,\n",
       " 1.0]"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_feature_vector(train_dataset.iloc[0], vocabulary_sarcastic, vocabulary_regular, analyzer, constituency_parser, keyword_extractor, similarity_pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 1/1003 [00:01<30:20,  1.82s/it]/var/folders/7r/d3_ly2ln4yn7612_mtn24q0h0000gn/T/ipykernel_87762/458134087.py:24: UserWarning: [W008] Evaluating Doc.similarity based on empty vectors.\n",
      "  similarities.append(similarity_pipeline(word_title).similarity(similarity_pipeline(word_review[0])))\n",
      "100%|██████████| 1003/1003 [15:23<00:00,  1.09it/s]\n",
      "100%|██████████| 125/125 [01:54<00:00,  1.09it/s]\n",
      "100%|██████████| 126/126 [01:58<00:00,  1.06it/s]\n"
     ]
    }
   ],
   "source": [
    "feature_vectors_train = list()\n",
    "feature_vectors_val = list()\n",
    "feature_vectors_test = list()\n",
    "for i in tqdm(range(len(train_dataset))):\n",
    "    feature_vectors_train.append(get_feature_vector(train_dataset.iloc[i], vocabulary_sarcastic, vocabulary_regular, analyzer, constituency_parser, keyword_extractor, similarity_pipeline))\n",
    "\n",
    "for i in tqdm(range(len(val_dataset))):\n",
    "    feature_vectors_val.append(get_feature_vector(val_dataset.iloc[i], vocabulary_sarcastic, vocabulary_regular, analyzer, constituency_parser, keyword_extractor, similarity_pipeline))\n",
    "\n",
    "for i in tqdm(range(len(test_dataset))):\n",
    "    feature_vectors_test.append(get_feature_vector(test_dataset.iloc[i], vocabulary_sarcastic, vocabulary_regular, analyzer, constituency_parser, keyword_extractor, similarity_pipeline))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.9995, 0.4, 0.044444444444444446, 0.022222222222222223, 0.5333333333333333, 0.11348464619492657, 0.102803738317757, 0.08945260347129506, 0.06275033377837116, 0.66, 0.26, 0.06, 0.02, 3.9987500000000002, 0.07309403448939084, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(feature_vectors_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save feature vectors to numpy files\n",
    "np.save('feature_vectors_train.npy', feature_vectors_train)\n",
    "np.save('feature_vectors_val.npy', feature_vectors_val)\n",
    "np.save('feature_vectors_test.npy', feature_vectors_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform SVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read data from numpy files\n",
    "feature_vectors_train_read = np.load('feature_vectors_train.npy')\n",
    "feature_vectors_val_read = np.load('feature_vectors_val.npy')\n",
    "feature_vectors_test_read = np.load('feature_vectors_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.89      0.89        84\n",
      "           1       0.78      0.78      0.78        41\n",
      "\n",
      "    accuracy                           0.86       125\n",
      "   macro avg       0.84      0.84      0.84       125\n",
      "weighted avg       0.86      0.86      0.86       125\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.88      0.88        90\n",
      "           1       0.70      0.72      0.71        36\n",
      "\n",
      "    accuracy                           0.83       126\n",
      "   macro avg       0.80      0.80      0.80       126\n",
      "weighted avg       0.83      0.83      0.83       126\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:605: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype):\n",
      "/Users/hugobouy/miniconda3/envs/dl_project/lib/python3.11/site-packages/sklearn/utils/validation.py:614: FutureWarning: is_sparse is deprecated and will be removed in a future version. Check `isinstance(dtype, pd.SparseDtype)` instead.\n",
      "  if is_sparse(pd_dtype) or not is_extension_array_dtype(pd_dtype):\n"
     ]
    }
   ],
   "source": [
    "from sklearn import svm\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "clf = svm.SVC(kernel='linear')\n",
    "clf.fit(feature_vectors_train_read, train_dataset['is_sarcastic'])\n",
    "\n",
    "y_pred = clf.predict(feature_vectors_val_read)\n",
    "print(classification_report(val_dataset['is_sarcastic'], y_pred))\n",
    "\n",
    "y_pred = clf.predict(feature_vectors_test_read)\n",
    "print(classification_report(test_dataset['is_sarcastic'], y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl_project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
