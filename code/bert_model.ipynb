{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  is_sarcastic\n",
       "0  thirtysomething scientists unveil doomsday clo...           1.0\n",
       "1  dem rep. totally nails why congress is falling...           0.0\n",
       "2  eat your veggies: 9 deliciously different recipes           0.0\n",
       "3  inclement weather prevents liar from getting t...           1.0\n",
       "4  mother comes pretty close to using word 'strea...           1.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"../datasets/combined.parquet\"\n",
    "data = pd.read_parquet(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset for a quick overview\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sentence        0\n",
       " is_sarcastic    0\n",
       " dtype: int64,\n",
       " is_sarcastic\n",
       " 0.0    0.521391\n",
       " 1.0    0.478609\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any null values in the dataset\n",
    "null_check = data.isnull().sum()\n",
    "\n",
    "# Checking the distribution of the 'is_sarcastic' column\n",
    "label_distribution = data[\"is_sarcastic\"].value_counts(normalize=True)\n",
    "\n",
    "null_check, label_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28322, 6069, 6070)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data cleaning: removing special characters and escape sequences from the sentences\n",
    "data[\"sentence\"] = data[\"sentence\"].apply(lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x))\n",
    "\n",
    "# Splitting the dataset into training, validation, and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Showing the size of each split\n",
    "train_size, val_size, test_size = len(train_data), len(val_data), len(test_data)\n",
    "train_size, val_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remikalbe/.pyenv/versions/3.10.4/envs/iit_dl_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'sentence': [\"you will never love anything as much as dc's panda loves snow\",\n",
       "  \"the currys' nursery for their second baby is freaking adorable\",\n",
       "  '10 ways to deal with a difficult coworker',\n",
       "  'increasingly anxious man worried order confirmation email never going to come',\n",
       "  'learning resilience from a master',\n",
       "  \"dunno... feind seems to be a german surname. perhaps a feindslayer is someone who goes around killing people named feind? i'm happy being viewed as a fiend, however. not so easily slayed! ;)\",\n",
       "  'Yea, i got one about the UK. Let me find it, hold on.',\n",
       "  'man turns vegetarian for 36 hours',\n",
       "  \"this is the fall checklist your home's been waiting for\",\n",
       "  'How about, \"I think it\\'s a good idea\"?As Jito said, maybe YOU can\\'t, but I guess that\\'s your problem.',\n",
       "  'study links meat, sugar consumption to early death among those who choose to be happy in life',\n",
       "  \"Among other things, generally adaptions to a colder environment.   As for your theory as a whole, doesn't the whole 15, 000 year gap between the extinction of the Neanderthalls and the development of farming (particularly the grains youre talking about).\",\n",
       "  'nobel prize winners demand better health care for victims of sexual violence in colombia',\n",
       "  \"hurricane harvey is just the latest in facebook's fake news problem\",\n",
       "  'i love that you guys dont seem to be joking when you talk about it being offensive to gays - if anything i would think only tom cruise would find it offensive - because of his claims that he isnt gay (obviously untrue) gays would probably cheer if he (along with his penis) would come out of the closet if someone would find this offensive, it wouldnt be me vs gay guys - it would be me vs overly sensitive and selfrighteous guys who happen to be gay',\n",
       "  'breaking: fuck, fuck, fuck, this got out of hand'],\n",
       " 'input_ids': tensor([[  101,  2017,  2097,  ...,     0,     0,     0],\n",
       "         [  101,  1996, 15478,  ...,     0,     0,     0],\n",
       "         [  101,  2184,  3971,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  7064,  7702,  ...,     0,     0,     0],\n",
       "         [  101,  1045,  2293,  ...,     0,     0,     0],\n",
       "         [  101,  4911,  1024,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1])}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "class SarcasticSentencesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset for the sarcastic sentences dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sentence = str(self.sentences[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        # Encoding the sentences using the tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",  # Return PyTorch tensors\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"sentence\": sentence,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "# Constants\n",
    "MAX_LEN = 128  # Maximum length of the tokens list\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Creating instances of the SarcasticSentencesDataset\n",
    "train_dataset = SarcasticSentencesDataset(\n",
    "    train_data[\"sentence\"].to_numpy(),\n",
    "    train_data[\"is_sarcastic\"].to_numpy(),\n",
    "    tokenizer,\n",
    "    MAX_LEN,\n",
    ")\n",
    "\n",
    "val_dataset = SarcasticSentencesDataset(\n",
    "    val_data[\"sentence\"].to_numpy(),\n",
    "    val_data[\"is_sarcastic\"].to_numpy(),\n",
    "    tokenizer,\n",
    "    MAX_LEN,\n",
    ")\n",
    "\n",
    "test_dataset = SarcasticSentencesDataset(\n",
    "    test_data[\"sentence\"].to_numpy(),\n",
    "    test_data[\"is_sarcastic\"].to_numpy(),\n",
    "    tokenizer,\n",
    "    MAX_LEN,\n",
    ")\n",
    "\n",
    "# Creating the DataLoaders for training, validation, and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Checking the first batch from the train_loader\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm  # for displaying progress\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Module, CrossEntropyLoss\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: Module,\n",
    "    data_loader: DataLoader,\n",
    "    optimizer: Optimizer,\n",
    "    device: torch.device,\n",
    "    scheduler: _LRScheduler,\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    n_examples: int,\n",
    ") -> Dict[str, float]:\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Initialize counters\n",
    "    tp_sarcasm = 0\n",
    "    tn_non_sarcasm = 0\n",
    "    fp_sarcasm = 0\n",
    "    fn_sarcasm = 0\n",
    "\n",
    "    for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "        # Update TP, TN, FP, FN counters\n",
    "        tp_sarcasm += torch.sum((preds == 1) & (labels == 1)).item()\n",
    "        tn_non_sarcasm += torch.sum((preds == 0) & (labels == 0)).item()\n",
    "        fp_sarcasm += torch.sum((preds == 1) & (labels == 0)).item()\n",
    "        fn_sarcasm += torch.sum((preds == 0) & (labels == 1)).item()\n",
    "\n",
    "    # Compute precision and recall for sarcasm\n",
    "    precision_sarcasm = tp_sarcasm / (tp_sarcasm + fp_sarcasm + 1e-10)\n",
    "    recall_sarcasm = tp_sarcasm / (tp_sarcasm + fn_sarcasm + 1e-10)\n",
    "\n",
    "    # Compute precision and recall for non-sarcasm\n",
    "    precision_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fn_sarcasm + 1e-10)\n",
    "    recall_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fp_sarcasm + 1e-10)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_predictions.float() / n_examples,\n",
    "        \"precision_sarcasm\": precision_sarcasm,\n",
    "        \"recall_sarcasm\": recall_sarcasm,\n",
    "        \"precision_non_sarcasm\": precision_non_sarcasm,\n",
    "        \"recall_non_sarcasm\": recall_non_sarcasm,\n",
    "        \"loss\": np.mean(losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(\n",
    "    model: Module,\n",
    "    data_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    n_examples: int,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Initialize counters\n",
    "    tp_sarcasm = 0\n",
    "    tn_non_sarcasm = 0\n",
    "    fp_sarcasm = 0\n",
    "    fn_sarcasm = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "            # Update TP, TN, FP, FN counters\n",
    "            tp_sarcasm += torch.sum((preds == 1) & (labels == 1)).item()\n",
    "            tn_non_sarcasm += torch.sum((preds == 0) & (labels == 0)).item()\n",
    "            fp_sarcasm += torch.sum((preds == 1) & (labels == 0)).item()\n",
    "            fn_sarcasm += torch.sum((preds == 0) & (labels == 1)).item()\n",
    "\n",
    "    # Compute precision and recall for sarcasm\n",
    "    precision_sarcasm = tp_sarcasm / (tp_sarcasm + fp_sarcasm + 1e-10)\n",
    "    recall_sarcasm = tp_sarcasm / (tp_sarcasm + fn_sarcasm + 1e-10)\n",
    "\n",
    "    # Compute precision and recall for non-sarcasm\n",
    "    precision_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fn_sarcasm + 1e-10)\n",
    "    recall_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fp_sarcasm + 1e-10)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_predictions.float() / n_examples,\n",
    "        \"precision_sarcasm\": precision_sarcasm,\n",
    "        \"recall_sarcasm\": recall_sarcasm,\n",
    "        \"precision_non_sarcasm\": precision_non_sarcasm,\n",
    "        \"recall_non_sarcasm\": recall_non_sarcasm,\n",
    "        \"loss\": np.mean(losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/remikalbe/.pyenv/versions/3.10.4/envs/iit_dl_project/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [08:50<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Loss: 0.4276 | Accuracy: 0.7969 | Sarcasm Precision: 0.7885 | Sarcasm Recall: 0.7866 | Non-Sarcasm Precision: 0.8046 | Non-Sarcasm Recall: 0.8064\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:30<00:00, 12.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Loss: 0.3986 | Accuracy: 0.8290 | Sarcasm Precision: 0.9071 | Sarcasm Recall: 0.7195 | Non-Sarcasm Precision: 0.7805 | Non-Sarcasm Recall: 0.9312\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [08:50<00:00,  3.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Loss: 0.3060 | Accuracy: 0.8642 | Sarcasm Precision: 0.8578 | Sarcasm Recall: 0.8585 | Non-Sarcasm Precision: 0.8701 | Non-Sarcasm Recall: 0.8695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:30<00:00, 12.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Loss: 0.3703 | Accuracy: 0.8448 | Sarcasm Precision: 0.9021 | Sarcasm Recall: 0.7611 | Non-Sarcasm Precision: 0.8054 | Non-Sarcasm Recall: 0.9229\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [09:03<00:00,  3.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Loss: 0.2534 | Accuracy: 0.8900 | Sarcasm Precision: 0.8833 | Sarcasm Recall: 0.8873 | Non-Sarcasm Precision: 0.8962 | Non-Sarcasm Recall: 0.8924\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:32<00:00, 11.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Loss: 0.3695 | Accuracy: 0.8479 | Sarcasm Precision: 0.9131 | Sarcasm Recall: 0.7570 | Non-Sarcasm Precision: 0.8044 | Non-Sarcasm Recall: 0.9328\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model = BertForSequenceClassification.from_pretrained(\n",
    "    \"bert-base-uncased\",\n",
    "    num_labels=2,\n",
    "    hidden_dropout_prob=0.3,  # dropout rate,\n",
    "    attention_probs_dropout_prob=0.3,  # dropout rate in attention heads\n",
    ")\n",
    "model.to(device)  # Send the model to GPU if available\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(\n",
    "    model.parameters(), lr=2e-5, weight_decay=0.01  # weight decay for regularization\n",
    ")\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "# Total number of training steps\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "\n",
    "# Scheduler for learning rate\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Training and Validation\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    # Training phase\n",
    "    train_output = train_epoch(\n",
    "        model, train_loader, optimizer, device, scheduler, loss_fn, len(train_dataset)\n",
    "    )\n",
    "\n",
    "    print(f\"Training Metrics:\")\n",
    "    train_metrics = [\n",
    "        f\"Loss: {train_output['loss']:.4f}\",\n",
    "        f\"Accuracy: {train_output['accuracy']:.4f}\",\n",
    "        f\"Sarcasm Precision: {train_output['precision_sarcasm']:.4f}\",\n",
    "        f\"Sarcasm Recall: {train_output['recall_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Precision: {train_output['precision_non_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Recall: {train_output['recall_non_sarcasm']:.4f}\",\n",
    "    ]\n",
    "    print(\" | \".join(train_metrics))\n",
    "\n",
    "    # Validation phase\n",
    "    val_output = eval_model(model, val_loader, device, loss_fn, len(val_dataset))\n",
    "\n",
    "    print(f\"Validation Metrics:\")\n",
    "    val_metrics = [\n",
    "        f\"Loss: {val_output['loss']:.4f}\",\n",
    "        f\"Accuracy: {val_output['accuracy']:.4f}\",\n",
    "        f\"Sarcasm Precision: {val_output['precision_sarcasm']:.4f}\",\n",
    "        f\"Sarcasm Recall: {val_output['recall_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Precision: {val_output['precision_non_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Recall: {val_output['recall_non_sarcasm']:.4f}\",\n",
    "    ]\n",
    "    print(\" | \".join(val_metrics))\n",
    "\n",
    "    print()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"sarcastic_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
