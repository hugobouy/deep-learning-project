{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm detection with BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tunning on a combination of datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  is_sarcastic\n",
       "0  thirtysomething scientists unveil doomsday clo...           1.0\n",
       "1  dem rep. totally nails why congress is falling...           0.0\n",
       "2  eat your veggies: 9 deliciously different recipes           0.0\n",
       "3  inclement weather prevents liar from getting t...           1.0\n",
       "4  mother comes pretty close to using word 'strea...           1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "combined_df_file_path = \"../datasets/combined.parquet\"\n",
    "combined_df = pd.read_parquet(combined_df_file_path)\n",
    "\n",
    "# Display the first few rows of the dataset for a quick overview\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some statistics and cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sentence        0\n",
       " is_sarcastic    0\n",
       " dtype: int64,\n",
       " is_sarcastic\n",
       " 0.0    0.521391\n",
       " 1.0    0.478609\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any null values in the dataset\n",
    "combined_df_null_check = combined_df.isnull().sum()\n",
    "\n",
    "# Data cleaning: removing special characters and escape sequences from the sentences\n",
    "combined_df[\"sentence\"] = combined_df[\"sentence\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "\n",
    "# Checking the distribution of the 'is_sarcastic' column\n",
    "combined_df_label_distribution = combined_df[\"is_sarcastic\"].value_counts(\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "combined_df_null_check, combined_df_label_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28322, 6069, 6070)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation, and testing sets\n",
    "combined_train_data, combined_test_data = train_test_split(\n",
    "    combined_df, test_size=0.3, random_state=42\n",
    ")\n",
    "combined_val_data, combined_test_data = train_test_split(\n",
    "    combined_test_data, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Showing the size of each split\n",
    "combined_train_size, combined_val_size, combined_test_size = (\n",
    "    len(combined_train_data),\n",
    "    len(combined_val_data),\n",
    "    len(combined_test_data),\n",
    ")\n",
    "combined_train_size, combined_val_size, combined_test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataset class for the BertTokenizer & PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remikalbe/.pyenv/versions/3.10.4/envs/iit_dl_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcasticSentencesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset for the sarcastic sentences dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sentence = str(self.sentences[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        # Encoding the sentences using the tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",  # Return PyTorch tensors\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"sentence\": sentence,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': [\"The meticulously preserved, unchanging 66 Books of the Bible aren't compelling?\",\n",
       "  \"And I'm sure you of all people know the mind of God... Please, you just take snippets of scripture, and twist it into well this is absolute. God loves gays and lesbians, but you fling god out as a way to justify your slander and bigotry.  \",\n",
       "  'exclusive: bet responds after coming under fire from journalists and publicists',\n",
       "  \"saving the world's last 3 northern white rhino\",\n",
       "  'allies: islamist motive for killing nemtsov is nonsense',\n",
       "  'laid-off zoologist goes on tranquilizing rampage',\n",
       "  'annoying man more annoying after skydiving',\n",
       "  'paris terror harms france, islam, and the world',\n",
       "  \"former patriots and chiefs tackle ryan o'callaghan comes out as gay\",\n",
       "  '\"Placeholder\" would honestly be a better name than Pied Piper.',\n",
       "  \"snapchat's snapcash: is peer-to-peer payment safe?\",\n",
       "  'grown man purchases 37th sailor moon figurine',\n",
       "  'why we should tip service workers generously',\n",
       "  'emoticonXFrazzledTalk about a fast and loose accusation.WHAT DID HE ACTUALLY SAY???Cause Harry Hay is well known for his gay rights work.If Jennings did find something about the guy inspiring, it was probably his gay rights work.If I said that I thought Martin Luther King Jr was inspiring, would you automatically associate my praise with extramarital affairs?This is just stupid!',\n",
       "  \"'bubble boy' finally comfortable in his own skin\",\n",
       "  'experts caution new car loses 90% of value as soon as you drive it off cliff'],\n",
       " 'input_ids': tensor([[  101,  1996,  2777,  ...,     0,     0,     0],\n",
       "         [  101,  1998,  1045,  ...,     0,     0,     0],\n",
       "         [  101,  7262,  1024,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  7861, 20214,  ...,     0,     0,     0],\n",
       "         [  101,  1005, 11957,  ...,     0,     0,     0],\n",
       "         [  101,  8519, 14046,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the BERT tokenizer\n",
    "bert_base_uncased_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Constants\n",
    "COMBINED_MAX_LEN = 128  # Maximum length of the tokens list\n",
    "COMBINED_BATCH_SIZE = 16\n",
    "\n",
    "# Creating instances of the SarcasticSentencesDataset\n",
    "combined_train_dataset = SarcasticSentencesDataset(\n",
    "    combined_train_data[\"sentence\"].to_numpy(),\n",
    "    combined_train_data[\"is_sarcastic\"].to_numpy(),\n",
    "    bert_base_uncased_tokenizer,\n",
    "    COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "combined_val_dataset = SarcasticSentencesDataset(\n",
    "    combined_val_data[\"sentence\"].to_numpy(),\n",
    "    combined_val_data[\"is_sarcastic\"].to_numpy(),\n",
    "    bert_base_uncased_tokenizer,\n",
    "    COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "combined_test_dataset = SarcasticSentencesDataset(\n",
    "    combined_test_data[\"sentence\"].to_numpy(),\n",
    "    combined_test_data[\"is_sarcastic\"].to_numpy(),\n",
    "    bert_base_uncased_tokenizer,\n",
    "    COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "# Creating the DataLoaders for training, validation, and testing\n",
    "combined_train_loader = DataLoader(\n",
    "    combined_train_dataset, batch_size=COMBINED_BATCH_SIZE, shuffle=True\n",
    ")\n",
    "combined_val_loader = DataLoader(combined_val_dataset, batch_size=COMBINED_BATCH_SIZE)\n",
    "combined_test_loader = DataLoader(combined_test_dataset, batch_size=COMBINED_BATCH_SIZE)\n",
    "\n",
    "# Checking the first batch from the train_loader\n",
    "next(iter(combined_train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the train and validation loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss, Module\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler, LambdaLR\n",
    "\n",
    "# Transformers imports\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "# Typing imports\n",
    "from typing import Dict, Optional, List, Union\n",
    "\n",
    "# Other libraries\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device: torch.device = torch.device(\n",
    "    device=\"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: Module,\n",
    "    data_loader: DataLoader,\n",
    "    optimizer: Optimizer,\n",
    "    device: torch.device,\n",
    "    scheduler: Union[_LRScheduler, LambdaLR],\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    n_examples: int,\n",
    "    feature_keys: Optional[List[str]] = None,  # List of keys if present\n",
    ") -> Dict[str, float]:\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = torch.Tensor([0]).to(device)\n",
    "\n",
    "    # For calculating precision and recall\n",
    "    tp_sarcasm = 0\n",
    "    tn_non_sarcasm = 0\n",
    "    fp_sarcasm = 0\n",
    "    fn_sarcasm = 0\n",
    "\n",
    "    for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "        # Process inputs for single/multiple features\n",
    "        inputs = (\n",
    "            {key: batch[key].to(device) for key in feature_keys}\n",
    "            if feature_keys\n",
    "            else {\n",
    "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "                \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "            }\n",
    "        )\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "        # Update TP, TN, FP, FN counters\n",
    "        tp_sarcasm += (preds & labels).sum().item()\n",
    "        tn_non_sarcasm += ((~preds.byte()) & (~labels.byte())).sum().item()\n",
    "        fp_sarcasm += (preds & (~labels.byte())).sum().item()\n",
    "        fn_sarcasm += ((~preds.byte()) & labels).sum().item()\n",
    "\n",
    "    # Calculate precision and recall for sarcasm class\n",
    "    precision_sarcasm = tp_sarcasm / (tp_sarcasm + fp_sarcasm)\n",
    "    recall_sarcasm = tp_sarcasm / (tp_sarcasm + fn_sarcasm)\n",
    "\n",
    "    # Calculate precision and recall for non-sarcasm class\n",
    "    precision_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fn_sarcasm)\n",
    "    recall_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fp_sarcasm)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_predictions.float().item() / n_examples,\n",
    "        \"precision_sarcasm\": precision_sarcasm,\n",
    "        \"recall_sarcasm\": recall_sarcasm,\n",
    "        \"precision_non_sarcasm\": precision_non_sarcasm,\n",
    "        \"recall_non_sarcasm\": recall_non_sarcasm,\n",
    "        \"loss\": np.mean(losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(\n",
    "    model: Module,\n",
    "    data_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    n_examples: int,\n",
    "    feature_keys: Optional[List[str]] = None,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = torch.Tensor([0]).to(device)\n",
    "\n",
    "    # Initialize counters for precision and recall\n",
    "    tp_sarcasm = 0\n",
    "    tn_non_sarcasm = 0\n",
    "    fp_sarcasm = 0\n",
    "    fn_sarcasm = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "            # Process inputs for single/multiple features\n",
    "            inputs = (\n",
    "                {key: batch[key].to(device) for key in feature_keys}\n",
    "                if feature_keys\n",
    "                else {\n",
    "                    \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "                    \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "                }\n",
    "            )\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "            # Update TP, TN, FP, FN counters for precision and recall calculations\n",
    "            tp_sarcasm += (preds & labels).sum().item()\n",
    "            tn_non_sarcasm += ((~preds.byte()) & (~labels.byte())).sum().item()\n",
    "            fp_sarcasm += (preds & (~labels.byte())).sum().item()\n",
    "            fn_sarcasm += ((~preds.byte()) & labels).sum().item()\n",
    "\n",
    "    # Calculate precision and recall for sarcasm class\n",
    "    precision_sarcasm = tp_sarcasm / (tp_sarcasm + fp_sarcasm)\n",
    "    recall_sarcasm = tp_sarcasm / (tp_sarcasm + fn_sarcasm)\n",
    "\n",
    "    # Calculate precision and recall for non-sarcasm class\n",
    "    precision_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fn_sarcasm)\n",
    "    recall_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fp_sarcasm)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_predictions.float().item() / n_examples,\n",
    "        \"precision_sarcasm\": precision_sarcasm,\n",
    "        \"recall_sarcasm\": recall_sarcasm,\n",
    "        \"precision_non_sarcasm\": precision_non_sarcasm,\n",
    "        \"recall_non_sarcasm\": recall_non_sarcasm,\n",
    "        \"loss\": np.mean(losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & evaluation of the model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/remikalbe/.pyenv/versions/3.10.4/envs/iit_dl_project/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [09:58<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Loss: 0.4146 | Accuracy: 0.8031 | Sarcasm Precision: 0.7991 | Sarcasm Recall: 0.7860 | Non-Sarcasm Precision: 0.9996 | Non-Sarcasm Recall: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:40<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Loss: 0.3539 | Accuracy: 0.8423 | Sarcasm Precision: 0.8892 | Sarcasm Recall: 0.7693 | Non-Sarcasm Precision: 0.9996 | Non-Sarcasm Recall: 0.9998\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 1125/1771 [07:08<04:08,  2.60it/s]"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "\n",
    "COMBINED_PRETRAINED_MODEL_NAME_OR_PATH = \"bert-base-uncased\"\n",
    "COMBINED_NUM_LABELS = 2  # Number of labels in the dataset\n",
    "COMBINED_HIDDEN_DROPOUT_PROB = 0.3  # Dropout rate\n",
    "COMBINED_ATTENTION_PROBS_DROPOUT_PROB = 0.3  # Dropout rate in attention heads\n",
    "COMBINED_NUM_EPOCHS = 3  # Number of epochs\n",
    "COMBINED_LR = 2e-5  # Learning rate\n",
    "COMBINED_WEIGHT_DECAY = 0.01  # Weight decay for regularization\n",
    "COMBINED_NUM_WARMUP_STEPS = 0  # Number of warmup steps for learning rate scheduler\n",
    "\n",
    "# Load pre-trained model\n",
    "combined_model = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=COMBINED_PRETRAINED_MODEL_NAME_OR_PATH,\n",
    "    num_labels=COMBINED_NUM_LABELS,\n",
    "    hidden_dropout_prob=COMBINED_HIDDEN_DROPOUT_PROB,  # dropout rate,\n",
    "    attention_probs_dropout_prob=COMBINED_ATTENTION_PROBS_DROPOUT_PROB,  # dropout rate in attention heads\n",
    ")\n",
    "\n",
    "# For typing purposes, check if model is an instance of Module\n",
    "if not isinstance(combined_model, Module):\n",
    "    raise ValueError(\"Model must be an instance of Module\")\n",
    "\n",
    "# Send the model to GPU if available\n",
    "combined_model.to(device=device)  # type: ignore\n",
    "\n",
    "# Optimizer\n",
    "combined_optimizer = AdamW(\n",
    "    combined_model.parameters(), lr=COMBINED_LR, weight_decay=COMBINED_WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Total number of training steps\n",
    "combined_total_steps = len(combined_train_loader) * COMBINED_NUM_EPOCHS\n",
    "\n",
    "# Scheduler for learning rate\n",
    "combined_scheduler = get_linear_schedule_with_warmup(\n",
    "    combined_optimizer,\n",
    "    num_warmup_steps=COMBINED_NUM_WARMUP_STEPS,\n",
    "    num_training_steps=combined_total_steps,\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "combined_loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Feature keys\n",
    "combined_feature_keys = [\"input_ids\", \"attention_mask\"]\n",
    "\n",
    "# Training and Validation\n",
    "for epoch in range(COMBINED_NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{COMBINED_NUM_EPOCHS}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    # Training phase\n",
    "    train_output = train_epoch(\n",
    "        model=combined_model,\n",
    "        data_loader=combined_train_loader,\n",
    "        optimizer=combined_optimizer,\n",
    "        device=device,\n",
    "        scheduler=combined_scheduler,\n",
    "        loss_fn=combined_loss_fn,\n",
    "        n_examples=len(combined_train_dataset),\n",
    "        feature_keys=combined_feature_keys,\n",
    "    )\n",
    "\n",
    "    print(f\"Training Metrics:\")\n",
    "    train_metrics = [\n",
    "        f\"Loss: {train_output['loss']:.4f}\",\n",
    "        f\"Accuracy: {train_output['accuracy']:.4f}\",\n",
    "        f\"Sarcasm Precision: {train_output['precision_sarcasm']:.4f}\",\n",
    "        f\"Sarcasm Recall: {train_output['recall_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Precision: {train_output['precision_non_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Recall: {train_output['recall_non_sarcasm']:.4f}\",\n",
    "    ]\n",
    "    print(\" | \".join(train_metrics))\n",
    "\n",
    "    # Validation phase\n",
    "    val_output = eval_model(\n",
    "        model=combined_model,\n",
    "        data_loader=combined_val_loader,\n",
    "        device=device,\n",
    "        loss_fn=combined_loss_fn,\n",
    "        n_examples=len(combined_val_dataset),\n",
    "        feature_keys=combined_feature_keys,\n",
    "    )\n",
    "\n",
    "    print(f\"Validation Metrics:\")\n",
    "    val_metrics = [\n",
    "        f\"Loss: {val_output['loss']:.4f}\",\n",
    "        f\"Accuracy: {val_output['accuracy']:.4f}\",\n",
    "        f\"Sarcasm Precision: {val_output['precision_sarcasm']:.4f}\",\n",
    "        f\"Sarcasm Recall: {val_output['recall_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Precision: {val_output['precision_non_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Recall: {val_output['recall_non_sarcasm']:.4f}\",\n",
    "    ]\n",
    "    print(\" | \".join(val_metrics))\n",
    "\n",
    "    print()\n",
    "\n",
    "# Save the model\n",
    "PRETRAINED_BERT_PATH = \"sarcastic_model.pth\"\n",
    "torch.save(combined_model.state_dict(), PRETRAINED_BERT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new model based on the pre-trained BERT model, adding review features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset class for the new model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcasticProductReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class for sarcastic product reviews with multiple text features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review_data = self.data.iloc[idx]\n",
    "        label = review_data[\"is_sarcastic\"]\n",
    "\n",
    "        # Tokenizing each text feature separately\n",
    "        title_encoding = self.tokenize_text_feature(review_data[\"title\"])\n",
    "        author_encoding = self.tokenize_text_feature(review_data[\"author\"])\n",
    "        product_encoding = self.tokenize_text_feature(review_data[\"product\"])\n",
    "        review_encoding = self.tokenize_text_feature(review_data[\"review\"])\n",
    "\n",
    "        # Convert stars rating to a tensor\n",
    "        stars_rating = torch.tensor([float(review_data[\"stars\"])], dtype=torch.float)\n",
    "\n",
    "        return {\n",
    "            \"title_input_ids\": title_encoding[\"input_ids\"].flatten(),\n",
    "            \"title_attention_mask\": title_encoding[\"attention_mask\"].flatten(),\n",
    "            \"author_input_ids\": author_encoding[\"input_ids\"].flatten(),\n",
    "            \"author_attention_mask\": author_encoding[\"attention_mask\"].flatten(),\n",
    "            \"product_input_ids\": product_encoding[\"input_ids\"].flatten(),\n",
    "            \"product_attention_mask\": product_encoding[\"attention_mask\"].flatten(),\n",
    "            \"review_input_ids\": review_encoding[\"input_ids\"].flatten(),\n",
    "            \"review_attention_mask\": review_encoding[\"attention_mask\"].flatten(),\n",
    "            \"stars\": stars_rating.flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "    def tokenize_text_feature(self, text):\n",
    "        return self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,  # truncate or pad to max_len\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",  # pad to max_length\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",  # return tensors for PyTorch\n",
    "            truncation=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from transformers import BertModel\n",
    "import torch.nn as nn\n",
    "\n",
    "\n",
    "class ExtendedBertForMultiFeatureClassification(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_bert_path,\n",
    "        hidden_size,\n",
    "        num_labels,\n",
    "        hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob,\n",
    "        star_hidden_dropout_prob,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\n",
    "            pretrained_model_name_or_path=pretrained_bert_path,\n",
    "            num_labels=num_labels,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,  # dropout rate,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,  # dropout rate in attention heads\n",
    "        )\n",
    "        if not isinstance(self.bert, Module):\n",
    "            raise ValueError(\"Model must be an instance of Module\")\n",
    "\n",
    "        self.bert.load_state_dict(\n",
    "            torch.load(pretrained_bert_path, map_location=torch.device(\"cpu\"))\n",
    "        )\n",
    "\n",
    "        # Assuming features for title, author, product, review\n",
    "        num_features = 4  # how many text features we're combining\n",
    "\n",
    "        # The feature combiner layer (you could have more complex architecture here if necessary)\n",
    "        self.feature_combiner = nn.Linear(hidden_size * num_features, hidden_size)\n",
    "\n",
    "        # The classifier head\n",
    "        self.classifier = nn.Linear(\n",
    "            hidden_size + 1, num_labels\n",
    "        )  # +1 for the star rating feature\n",
    "        self.dropout = nn.Dropout(star_hidden_dropout_prob)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        title_input_ids,\n",
    "        title_attention_mask,\n",
    "        author_input_ids,\n",
    "        author_attention_mask,\n",
    "        product_input_ids,\n",
    "        product_attention_mask,\n",
    "        review_input_ids,\n",
    "        review_attention_mask,\n",
    "        stars,\n",
    "    ):\n",
    "        if not isinstance(self.bert, Module):\n",
    "            raise ValueError(\"Model must be an instance of Module\")\n",
    "\n",
    "        # Process each text input through the fine-tuned BERT independently\n",
    "        # Extract the last hidden state of the [CLS] token from each output\n",
    "        title_cls = self.bert(\n",
    "            title_input_ids, attention_mask=title_attention_mask\n",
    "        ).pooler_output\n",
    "        author_cls = self.bert(\n",
    "            author_input_ids, attention_mask=author_attention_mask\n",
    "        ).pooler_output\n",
    "        product_cls = self.bert(\n",
    "            product_input_ids, attention_mask=product_attention_mask\n",
    "        ).pooler_output\n",
    "        review_cls = self.bert(\n",
    "            review_input_ids, attention_mask=review_attention_mask\n",
    "        ).pooler_output\n",
    "\n",
    "        # Combine [CLS] token outputs for all text features\n",
    "        combined_cls = torch.cat(\n",
    "            (title_cls, author_cls, product_cls, review_cls), dim=1\n",
    "        )\n",
    "\n",
    "        # Apply dropout and pass through the combiner layer\n",
    "        combined_features = self.dropout(self.feature_combiner(combined_cls))\n",
    "\n",
    "        # Concatenate the stars rating to the combined text features\n",
    "        combined_input = torch.cat(\n",
    "            (combined_features, stars.unsqueeze(1)), dim=1\n",
    "        )  # Ensure stars has the correct shape\n",
    "        # Pass combined features through the final classifier layer\n",
    "        logits = self.classifier(combined_input)\n",
    "\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "amz_combined_file_path = \"../datasets/amazon_combined.parquet\"\n",
    "amz_combined_df = pd.read_parquet(amz_combined_file_path)\n",
    "\n",
    "# Display the first few rows of the dataset for a quick overview\n",
    "amz_combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data cleaning: removing special characters and escape sequences from the sentences\n",
    "amz_combined_df[\"sentence\"] = amz_combined_df[\"sentence\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "\n",
    "# Checking for any null values in the dataset\n",
    "amz_combined_null_check = amz_combined_df.isnull().sum()\n",
    "\n",
    "# Checking the distribution of the 'is_sarcastic' column\n",
    "amz_combined_label_distribution = amz_combined_df[\"is_sarcastic\"].value_counts(\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "amz_combined_null_check, amz_combined_label_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into training, validation, and testing sets\n",
    "amz_combined_train_data, amz_combined_test_data = train_test_split(\n",
    "    amz_combined_df, test_size=0.3, random_state=42\n",
    ")\n",
    "amz_combined_val_data, amz_combined_test_data = train_test_split(\n",
    "    amz_combined_test_data, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Showing the size of each split\n",
    "amz_combined_train_size, amz_combined_val_size, amz_combined_test_size = (\n",
    "    len(amz_combined_train_data),\n",
    "    len(amz_combined_val_data),\n",
    "    len(amz_combined_test_data),\n",
    ")\n",
    "amz_combined_train_size, amz_combined_val_size, amz_combined_test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "AMZ_COMBINED_PRETRAINED_MODEL_NAME_OR_PATH = COMBINED_PRETRAINED_MODEL_NAME_OR_PATH\n",
    "AMZ_COMBINED_NUM_LABELS = COMBINED_NUM_LABELS\n",
    "AMZ_COMBINED_HIDDEN_DROPOUT_PROB = COMBINED_HIDDEN_DROPOUT_PROB\n",
    "AMZ_COMBINED_ATTENTION_PROBS_DROPOUT_PROB = COMBINED_ATTENTION_PROBS_DROPOUT_PROB\n",
    "\n",
    "# Specific hyperparameters for the amz model\n",
    "AMZ_COMBINED_HIDDEN_SIZE = 768  # Default hidden size for BERT base\n",
    "AMZ_COMBINED_STAR_HIDDEN_DROPOUT_PROB = 0.3  # Dropout rate for the star rating feature\n",
    "\n",
    "# Instantiate the extended model\n",
    "amz_combined_model = ExtendedBertForMultiFeatureClassification(\n",
    "    pretrained_bert_path=AMZ_COMBINED_PRETRAINED_MODEL_NAME_OR_PATH,\n",
    "    hidden_size=AMZ_COMBINED_HIDDEN_SIZE,\n",
    "    num_labels=AMZ_COMBINED_NUM_LABELS,\n",
    "    hidden_dropout_prob=AMZ_COMBINED_HIDDEN_DROPOUT_PROB,\n",
    "    attention_probs_dropout_prob=AMZ_COMBINED_ATTENTION_PROBS_DROPOUT_PROB,\n",
    "    star_hidden_dropout_prob=AMZ_COMBINED_STAR_HIDDEN_DROPOUT_PROB,\n",
    ")\n",
    "\n",
    "# Send the model to GPU if available\n",
    "amz_combined_model.to(device)  # type: ignore\n",
    "\n",
    "amz_combined_feature_keys = [\n",
    "    \"title_input_ids\",\n",
    "    \"title_attention_mask\",\n",
    "    \"author_input_ids\",\n",
    "    \"author_attention_mask\",\n",
    "    \"product_input_ids\",\n",
    "    \"product_attention_mask\",\n",
    "    \"review_input_ids\",\n",
    "    \"review_attention_mask\",\n",
    "    \"stars\",\n",
    "]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
