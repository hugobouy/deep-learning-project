{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm detection with BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tunning on a combination of datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  is_sarcastic\n",
       "0  thirtysomething scientists unveil doomsday clo...           1.0\n",
       "1  dem rep. totally nails why congress is falling...           0.0\n",
       "2  eat your veggies: 9 deliciously different recipes           0.0\n",
       "3  inclement weather prevents liar from getting t...           1.0\n",
       "4  mother comes pretty close to using word 'strea...           1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "combined_df_file_path = \"../datasets/combined.parquet\"\n",
    "combined_df = pd.read_parquet(combined_df_file_path)\n",
    "\n",
    "# Display the first few rows of the dataset for a quick overview\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some statistics and cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sentence        0\n",
       " is_sarcastic    0\n",
       " dtype: int64,\n",
       " is_sarcastic\n",
       " 0.0    0.521391\n",
       " 1.0    0.478609\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any null values in the dataset\n",
    "combined_df_null_check = combined_df.isnull().sum()\n",
    "\n",
    "# Data cleaning: removing special characters and escape sequences from the sentences\n",
    "combined_df[\"sentence\"] = combined_df[\"sentence\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "\n",
    "# Checking the distribution of the 'is_sarcastic' column\n",
    "combined_df_label_distribution = combined_df[\"is_sarcastic\"].value_counts(\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "combined_df_null_check, combined_df_label_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28322, 6069, 6070)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation, and testing sets\n",
    "combined_train_data, combined_test_data = train_test_split(\n",
    "    combined_df, test_size=0.3, random_state=42\n",
    ")\n",
    "combined_val_data, combined_test_data = train_test_split(\n",
    "    combined_test_data, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Showing the size of each split\n",
    "combined_train_size, combined_val_size, combined_test_size = (\n",
    "    len(combined_train_data),\n",
    "    len(combined_val_data),\n",
    "    len(combined_test_data),\n",
    ")\n",
    "combined_train_size, combined_val_size, combined_test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataset class for the BertTokenizer & PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remikalbe/.pyenv/versions/3.10.4/envs/iit_dl_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcasticSentencesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset for the sarcastic sentences dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sentence = str(self.sentences[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        # Encoding the sentences using the tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",  # Return PyTorch tensors\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"sentence\": sentence,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['ty cobb returns to old private practice in enchanted forest toadstool',\n",
       "  \"who needs the apple watch? this startup is building straps that make any regular watch 'smart'\",\n",
       "  \"And they could have experienced more without gun control. You're jumping to conclusions.\",\n",
       "  \"If you paid attention the BATFE said so.     Yes but some people don't want to close the borders. They prefer no border controls.\",\n",
       "  'double amputee proves he is capable of anything',\n",
       "  'Nothing I have stated is incorrect. If I did you would get specific.',\n",
       "  'koch network spent nearly $400 million in 2015',\n",
       "  \" Well, this is a record I heard daily in the spring days of 1994, but now, let's say it's some of the records I don't want to let any of my friends know I have. After the excellent ULTRAMEGA OK (just the title says all) and  the less excellent Badmotorfinger this must be considered as the complete  sell-out! The only really cool track is Ben Shepherd's &quot;Half&quot;. I  can't help thinking of pop-grunge fourteen year old girls with pierced  noses when I hear &quot;Black Hole Sun&quot;. Sad. \",\n",
       "  \"alittle over 5 years...? try 5 years this september. you know the people who did it?! then please call the fbi immediatly and tell them what you've discovered, because they can't prove osama bin laden had a connection to september 11, 2001.  that's correct. we carpet bombed afghanistan and overthrew the government we established there without having any evidence connecting osama bin laden to 9/11. and right, then we invaded iraq saying they were also some how connected as well. and you were so certain ubl attacked us? wow, you must be smarter than the entire american intelligence agency. sorry for my sarcastic response, but the mentality you're trying to push forward is except everything the government tells us and never question their motives or actions. please research alittle before posting something like this.\",\n",
       "  \"FSM is not world-wide yet, but it is growing. Thank you for the consciousness raising by bringing attention to this glorious belief system. It has the advantage of being every bit as valid and supportable as either creationism or ID. More importantly, it's scripture is unambiguous on the origins of the universe. It looks like you may have attracted a new adherent. Ramen!\",\n",
       "  \"why didn't you think of it? it took me no time at all to find the actual article, who authored it, and how to contact them. from what i have seen of your post, you rarely think at all.\",\n",
       "  'polling booth completely disgusting by time last voters get there',\n",
       "  \"So this time you are really serious about leaving emoticonXRolleyes  So now mental existence isn't good enough (as it is not unique which was my point) but human cells is important and something of a human brain. Well what importance are human cells and a human brain? It seems the idea of a human having importance is not just limited to me...you just happen to add another criteria at the end that you feel is important as well.\",\n",
       "  'Your denial is not serving you very well, Trebor. Also, try to learn to be something other than a dedicated kibbitzer for a change.',\n",
       "  \"how to hack your new year's resolution for success\",\n",
       "  \"I don't have the time nor the funding to put this in video form like Harris and Dawkins. I don't think many, if any, Christians really do - satire about atheism isn't a strong Christian practice, not nearly as strong as atheist satire about Christianity, it seems. Maybe that's what made Poe's Law so notable in the beginning of this thread.\"],\n",
       " 'input_ids': tensor([[  101,  5939, 17176,  ...,     0,     0,     0],\n",
       "         [  101,  2040,  3791,  ...,     0,     0,     0],\n",
       "         [  101,  1998,  2027,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2115, 14920,  ...,     0,     0,     0],\n",
       "         [  101,  2129,  2000,  ...,     0,     0,     0],\n",
       "         [  101,  1045,  2123,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the BERT tokenizer\n",
    "bert_base_uncased_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Constants\n",
    "COMBINED_MAX_LEN = 128 * 2\n",
    "COMBINED_BATCH_SIZE = 16\n",
    "\n",
    "# Creating instances of the SarcasticSentencesDataset\n",
    "combined_train_dataset = SarcasticSentencesDataset(\n",
    "    combined_train_data[\"sentence\"].to_numpy(),\n",
    "    combined_train_data[\"is_sarcastic\"].to_numpy(),\n",
    "    bert_base_uncased_tokenizer,\n",
    "    COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "combined_val_dataset = SarcasticSentencesDataset(\n",
    "    combined_val_data[\"sentence\"].to_numpy(),\n",
    "    combined_val_data[\"is_sarcastic\"].to_numpy(),\n",
    "    bert_base_uncased_tokenizer,\n",
    "    COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "combined_test_dataset = SarcasticSentencesDataset(\n",
    "    combined_test_data[\"sentence\"].to_numpy(),\n",
    "    combined_test_data[\"is_sarcastic\"].to_numpy(),\n",
    "    bert_base_uncased_tokenizer,\n",
    "    COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "# Creating the DataLoaders for training, validation, and testing\n",
    "combined_train_loader = DataLoader(\n",
    "    combined_train_dataset, batch_size=COMBINED_BATCH_SIZE, shuffle=True\n",
    ")\n",
    "combined_val_loader = DataLoader(combined_val_dataset, batch_size=COMBINED_BATCH_SIZE)\n",
    "combined_test_loader = DataLoader(combined_test_dataset, batch_size=COMBINED_BATCH_SIZE)\n",
    "\n",
    "# Checking the first batch from the train_loader\n",
    "next(iter(combined_train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the train and validation loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss, Module\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler, LambdaLR\n",
    "\n",
    "# Transformers imports\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "# Typing imports\n",
    "from typing import Dict, Optional, List, Union\n",
    "\n",
    "# Other libraries\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device: torch.device = torch.device(\n",
    "    device=\"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: Module,\n",
    "    data_loader: DataLoader,\n",
    "    optimizer: Optimizer,\n",
    "    device: torch.device,\n",
    "    scheduler: Union[_LRScheduler, LambdaLR],\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    n_examples: int,\n",
    "    feature_keys: Optional[List[str]] = None,  # List of keys if present\n",
    ") -> Dict[str, float]:\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = torch.Tensor([0]).to(device)\n",
    "\n",
    "    # For calculating precision and recall\n",
    "    tp_sarcasm = 0\n",
    "    tn_non_sarcasm = 0\n",
    "    fp_sarcasm = 0\n",
    "    fn_sarcasm = 0\n",
    "\n",
    "    for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "        # Process inputs for single/multiple features\n",
    "        inputs = (\n",
    "            {key: batch[key].to(device) for key in feature_keys}\n",
    "            if feature_keys\n",
    "            else {\n",
    "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "                \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "            }\n",
    "        )\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "        # Update TP, TN, FP, FN counters\n",
    "        tp_sarcasm += (preds & labels).sum().item()\n",
    "        tn_non_sarcasm += ((~preds.byte()) & (~labels.byte())).sum().item()\n",
    "        fp_sarcasm += (preds & (~labels.byte())).sum().item()\n",
    "        fn_sarcasm += ((~preds.byte()) & labels).sum().item()\n",
    "\n",
    "    # Calculate precision and recall for sarcasm class\n",
    "    precision_sarcasm = (\n",
    "        tp_sarcasm / (tp_sarcasm + fp_sarcasm) if (tp_sarcasm + fp_sarcasm) > 0 else 0\n",
    "    )\n",
    "    recall_sarcasm = (\n",
    "        tp_sarcasm / (tp_sarcasm + fn_sarcasm) if (tp_sarcasm + fn_sarcasm) > 0 else 0\n",
    "    )\n",
    "\n",
    "    # Calculate precision and recall for non-sarcasm class\n",
    "    precision_non_sarcasm = (\n",
    "        tn_non_sarcasm / (tn_non_sarcasm + fn_sarcasm)\n",
    "        if (tn_non_sarcasm + fn_sarcasm) > 0\n",
    "        else 0\n",
    "    )\n",
    "    recall_non_sarcasm = (\n",
    "        tn_non_sarcasm / (tn_non_sarcasm + fp_sarcasm)\n",
    "        if (tn_non_sarcasm + fp_sarcasm) > 0\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_predictions.float().item() / n_examples,\n",
    "        \"precision_sarcasm\": precision_sarcasm,\n",
    "        \"recall_sarcasm\": recall_sarcasm,\n",
    "        \"precision_non_sarcasm\": precision_non_sarcasm,\n",
    "        \"recall_non_sarcasm\": recall_non_sarcasm,\n",
    "        \"loss\": np.mean(losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(\n",
    "    model: Module,\n",
    "    data_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    n_examples: int,\n",
    "    feature_keys: Optional[List[str]] = None,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = torch.Tensor([0]).to(device)\n",
    "\n",
    "    # Initialize counters for precision and recall\n",
    "    tp_sarcasm = 0\n",
    "    tn_non_sarcasm = 0\n",
    "    fp_sarcasm = 0\n",
    "    fn_sarcasm = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "            # Process inputs for single/multiple features\n",
    "            inputs = (\n",
    "                {key: batch[key].to(device) for key in feature_keys}\n",
    "                if feature_keys\n",
    "                else {\n",
    "                    \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "                    \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "                }\n",
    "            )\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "            # Update TP, TN, FP, FN counters for precision and recall calculations\n",
    "            tp_sarcasm += (preds & labels).sum().item()\n",
    "            tn_non_sarcasm += ((~preds.byte()) & (~labels.byte())).sum().item()\n",
    "            fp_sarcasm += (preds & (~labels.byte())).sum().item()\n",
    "            fn_sarcasm += ((~preds.byte()) & labels).sum().item()\n",
    "\n",
    "    # Calculate precision and recall for sarcasm class\n",
    "    precision_sarcasm = (\n",
    "        tp_sarcasm / (tp_sarcasm + fp_sarcasm) if (tp_sarcasm + fp_sarcasm) > 0 else 0\n",
    "    )\n",
    "    recall_sarcasm = (\n",
    "        tp_sarcasm / (tp_sarcasm + fn_sarcasm) if (tp_sarcasm + fn_sarcasm) > 0 else 0\n",
    "    )\n",
    "\n",
    "    # Calculate precision and recall for non-sarcasm class\n",
    "    precision_non_sarcasm = (\n",
    "        tn_non_sarcasm / (tn_non_sarcasm + fn_sarcasm)\n",
    "        if (tn_non_sarcasm + fn_sarcasm) > 0\n",
    "        else 0\n",
    "    )\n",
    "    recall_non_sarcasm = (\n",
    "        tn_non_sarcasm / (tn_non_sarcasm + fp_sarcasm)\n",
    "        if (tn_non_sarcasm + fp_sarcasm) > 0\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_predictions.float().item() / n_examples,\n",
    "        \"precision_sarcasm\": precision_sarcasm,\n",
    "        \"recall_sarcasm\": recall_sarcasm,\n",
    "        \"precision_non_sarcasm\": precision_non_sarcasm,\n",
    "        \"recall_non_sarcasm\": recall_non_sarcasm,\n",
    "        \"loss\": np.mean(losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & evaluation of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the train and validation loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "    model: Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: Optimizer,\n",
    "    scheduler: Union[_LRScheduler, LambdaLR],\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    "    train_dataset_len: int,\n",
    "    val_dataset_len: int,\n",
    "    feature_keys: Optional[List[str]] = None,\n",
    "):\n",
    "    best_accuracy = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Training phase\n",
    "        train_output = train_epoch(\n",
    "            model=model,\n",
    "            data_loader=train_loader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            scheduler=scheduler,\n",
    "            loss_fn=loss_fn,\n",
    "            n_examples=train_dataset_len,\n",
    "            feature_keys=feature_keys,\n",
    "        )\n",
    "\n",
    "        train_metrics_str = \" | \".join(\n",
    "            f\"{metric}: {value:.4f}\" for metric, value in train_output.items()\n",
    "        )\n",
    "        print(f\"Training Metrics: {train_metrics_str}\")\n",
    "\n",
    "        # Validation phase\n",
    "        val_output = eval_model(\n",
    "            model=model,\n",
    "            data_loader=val_loader,\n",
    "            device=device,\n",
    "            loss_fn=loss_fn,\n",
    "            n_examples=val_dataset_len,\n",
    "            feature_keys=feature_keys,\n",
    "        )\n",
    "\n",
    "        val_metrics_str = \" | \".join(\n",
    "            f\"{metric}: {value:.4f}\" for metric, value in val_output.items()\n",
    "        )\n",
    "        print(f\"Validation Metrics: {val_metrics_str}\")\n",
    "\n",
    "        # Example: Save the best model based on validation accuracy\n",
    "        if val_output[\"accuracy\"] > best_accuracy:\n",
    "            best_accuracy = val_output[\"accuracy\"]\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Saved Best Model!\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_accuracy:.4f} on Epoch {best_epoch + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual training and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [22:13<00:00,  1.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics: accuracy: 0.7895 | precision_sarcasm: 0.7865 | recall_sarcasm: 0.7688 | precision_non_sarcasm: 0.9996 | recall_non_sarcasm: 0.9996 | loss: 0.4281\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [01:09<00:00,  5.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: accuracy: 0.8229 | precision_sarcasm: 0.8781 | recall_sarcasm: 0.7352 | precision_non_sarcasm: 0.9995 | recall_non_sarcasm: 0.9998 | loss: 0.3845\n",
      "Saved Best Model!\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [16:38<00:00,  1.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics: accuracy: 0.8686 | precision_sarcasm: 0.8590 | recall_sarcasm: 0.8678 | precision_non_sarcasm: 0.9998 | recall_non_sarcasm: 0.9997 | loss: 0.2979\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:58<00:00,  6.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: accuracy: 0.8459 | precision_sarcasm: 0.9189 | recall_sarcasm: 0.7468 | precision_non_sarcasm: 0.9995 | recall_non_sarcasm: 0.9999 | loss: 0.3560\n",
      "Saved Best Model!\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [16:17<00:00,  1.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics: accuracy: 0.8938 | precision_sarcasm: 0.8863 | recall_sarcasm: 0.8924 | precision_non_sarcasm: 0.9998 | recall_non_sarcasm: 0.9998 | loss: 0.2469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:57<00:00,  6.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: accuracy: 0.8494 | precision_sarcasm: 0.9138 | recall_sarcasm: 0.7597 | precision_non_sarcasm: 0.9995 | recall_non_sarcasm: 0.9999 | loss: 0.3627\n",
      "Saved Best Model!\n",
      "\n",
      "Best Validation Accuracy: 0.8494 on Epoch 3\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "COMBINED_PRETRAINED_MODEL_NAME_OR_PATH = \"bert-base-uncased\"\n",
    "COMBINED_NUM_LABELS = 2  # Number of labels in the dataset\n",
    "COMBINED_HIDDEN_DROPOUT_PROB = 0.3  # Dropout rate\n",
    "COMBINED_ATTENTION_PROBS_DROPOUT_PROB = 0.3  # Dropout rate in attention heads\n",
    "COMBINED_NUM_EPOCHS = 3  # Number of epochs\n",
    "COMBINED_LR = 2e-5  # Learning rate\n",
    "COMBINED_WEIGHT_DECAY = 0.01  # Weight decay for regularization\n",
    "COMBINED_NUM_WARMUP_STEPS = 0  # Number of warmup steps for learning rate scheduler\n",
    "\n",
    "# Load pre-trained model\n",
    "combined_model = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=COMBINED_PRETRAINED_MODEL_NAME_OR_PATH,\n",
    "    num_labels=COMBINED_NUM_LABELS,\n",
    "    hidden_dropout_prob=COMBINED_HIDDEN_DROPOUT_PROB,  # dropout rate,\n",
    "    attention_probs_dropout_prob=COMBINED_ATTENTION_PROBS_DROPOUT_PROB,  # dropout rate in attention heads\n",
    ")\n",
    "\n",
    "# For typing purposes, check if model is an instance of Module\n",
    "if not isinstance(combined_model, Module):\n",
    "    raise ValueError(\"Model must be an instance of Module\")\n",
    "\n",
    "# Send the model to GPU if available\n",
    "combined_model.to(device=device)  # type: ignore\n",
    "\n",
    "# Optimizer\n",
    "combined_optimizer = AdamW(\n",
    "    combined_model.parameters(), lr=COMBINED_LR, weight_decay=COMBINED_WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Total number of training steps\n",
    "combined_total_steps = len(combined_train_loader) * COMBINED_NUM_EPOCHS\n",
    "\n",
    "# Scheduler for learning rate\n",
    "combined_scheduler = get_linear_schedule_with_warmup(\n",
    "    combined_optimizer,\n",
    "    num_warmup_steps=COMBINED_NUM_WARMUP_STEPS,\n",
    "    num_training_steps=combined_total_steps,\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "combined_loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Feature keys\n",
    "combined_feature_keys = [\"input_ids\", \"attention_mask\"]\n",
    "\n",
    "# Train and evaluate the model\n",
    "train_and_evaluate(\n",
    "    model=combined_model,\n",
    "    train_loader=combined_train_loader,\n",
    "    val_loader=combined_val_loader,\n",
    "    optimizer=combined_optimizer,\n",
    "    scheduler=combined_scheduler,\n",
    "    loss_fn=combined_loss_fn,\n",
    "    device=device,\n",
    "    num_epochs=COMBINED_NUM_EPOCHS,\n",
    "    train_dataset_len=len(combined_train_dataset),\n",
    "    val_dataset_len=len(combined_val_dataset),\n",
    "    feature_keys=combined_feature_keys,\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "FINE_TUNED_BERT_PATH = \"sarcastic_model.pth\"\n",
    "torch.save(combined_model.state_dict(), FINE_TUNED_BERT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new model based on the pre-trained BERT model, adding review features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset class for the new model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcasticProductReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class for sarcastic product reviews with multiple text features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review_data = self.data.iloc[idx]\n",
    "        label = review_data[\"is_sarcastic\"]\n",
    "\n",
    "        # Tokenizing each text feature separately\n",
    "        title_encoding = self.tokenize_text_feature(review_data[\"title\"])\n",
    "        author_encoding = self.tokenize_text_feature(review_data[\"author\"])\n",
    "        product_encoding = self.tokenize_text_feature(review_data[\"product\"])\n",
    "        review_encoding = self.tokenize_text_feature(review_data[\"review\"])\n",
    "\n",
    "        # Convert stars rating to a tensor\n",
    "        stars_rating = torch.tensor([float(review_data[\"stars\"])], dtype=torch.float)\n",
    "\n",
    "        return {\n",
    "            \"title_input_ids\": title_encoding[\"input_ids\"].flatten(),\n",
    "            \"title_attention_mask\": title_encoding[\"attention_mask\"].flatten(),\n",
    "            \"author_input_ids\": author_encoding[\"input_ids\"].flatten(),\n",
    "            \"author_attention_mask\": author_encoding[\"attention_mask\"].flatten(),\n",
    "            \"product_input_ids\": product_encoding[\"input_ids\"].flatten(),\n",
    "            \"product_attention_mask\": product_encoding[\"attention_mask\"].flatten(),\n",
    "            \"review_input_ids\": review_encoding[\"input_ids\"].flatten(),\n",
    "            \"review_attention_mask\": review_encoding[\"attention_mask\"].flatten(),\n",
    "            \"stars\": stars_rating.flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "    def tokenize_text_feature(self, text):\n",
    "        return self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,  # truncate or pad to max_len\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",  # pad to max_length\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",  # return tensors for PyTorch\n",
    "            truncation=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Dropout, ReLU\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutput:\n",
    "    def __init__(self, logits):\n",
    "        self.logits = logits\n",
    "\n",
    "\n",
    "class ExtendedBertForMultiFeatureClassification(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_bert_path,\n",
    "        fine_tuned_bert_path,\n",
    "        hidden_size,\n",
    "        num_labels,\n",
    "        hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob,\n",
    "        classifier_dropout_prob,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\n",
    "            pretrained_model_name_or_path=pretrained_bert_path,\n",
    "            num_labels=num_labels,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,  # dropout rate,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,  # dropout rate in attention heads\n",
    "        )\n",
    "        if not isinstance(self.bert, Module):\n",
    "            raise ValueError(\"Model must be an instance of Module\")\n",
    "\n",
    "        # Load the state_dict from the saved model\n",
    "        state_dict = torch.load(fine_tuned_bert_path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "        # Remove the keys related to the classification head\n",
    "        state_dict = {\n",
    "            key: value\n",
    "            for key, value in state_dict.items()\n",
    "            if not key.startswith(\"classifier.\")\n",
    "        }\n",
    "\n",
    "        # Update the state with the weighed from the fine-tuned model (excluding classifier weights)\n",
    "        self.bert.load_state_dict(\n",
    "            state_dict, strict=False\n",
    "        )  # Set strict to False to ignore missing keys\n",
    "\n",
    "        # Assuming features for title, author, product, review\n",
    "        num_bert_features = 4  # how many BERT-encoded text features we're combining\n",
    "        num_additional_features = 1  # e.g., stars\n",
    "\n",
    "        # The feature combiner layer to merge BERT-encoded features\n",
    "        self.feature_combiner = Linear(\n",
    "            self.bert.config.hidden_size * num_bert_features, hidden_size\n",
    "        )\n",
    "        self.feature_combiner_activation = ReLU()\n",
    "\n",
    "        # The classifier head that includes an additional hidden layer\n",
    "        self.classifier_hidden = Linear(\n",
    "            hidden_size + num_additional_features, hidden_size\n",
    "        )\n",
    "        self.classifier_hidden_activation = ReLU()\n",
    "\n",
    "        # Final classification layer\n",
    "        self.classifier = Linear(hidden_size, num_labels)\n",
    "        self.dropout = Dropout(classifier_dropout_prob)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        title_input_ids,\n",
    "        title_attention_mask,\n",
    "        author_input_ids,\n",
    "        author_attention_mask,\n",
    "        product_input_ids,\n",
    "        product_attention_mask,\n",
    "        review_input_ids,\n",
    "        review_attention_mask,\n",
    "        stars,\n",
    "    ):\n",
    "        if not isinstance(self.bert, Module):\n",
    "            raise ValueError(\"Model must be an instance of Module\")\n",
    "\n",
    "        # Process each text input through the fine-tuned BERT independently\n",
    "        # Extract the last hidden state of the [CLS] token from each output\n",
    "        title_cls = self.bert(\n",
    "            title_input_ids, attention_mask=title_attention_mask\n",
    "        ).pooler_output\n",
    "        author_cls = self.bert(\n",
    "            author_input_ids, attention_mask=author_attention_mask\n",
    "        ).pooler_output\n",
    "        product_cls = self.bert(\n",
    "            product_input_ids, attention_mask=product_attention_mask\n",
    "        ).pooler_output\n",
    "        review_cls = self.bert(\n",
    "            review_input_ids, attention_mask=review_attention_mask\n",
    "        ).pooler_output\n",
    "\n",
    "        # Combine [CLS] token outputs for all text features\n",
    "        combined_cls = torch.cat(\n",
    "            (\n",
    "                title_cls,  # Should be (batch_size, hidden_size)\n",
    "                author_cls,  # Should be (batch_size, hidden_size)\n",
    "                product_cls,  # Should be (batch_size, hidden_size)\n",
    "                review_cls,  # Should be (batch_size, hidden_size)\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        # Make sure stars is 2D with shape (batch_size, 1)\n",
    "        stars = stars.unsqueeze(1) if stars.dim() == 1 else stars\n",
    "\n",
    "        # Apply dropout and pass through the affine transformation and activation\n",
    "        combined_features = self.dropout(\n",
    "            self.feature_combiner_activation(self.feature_combiner(combined_cls))\n",
    "        )\n",
    "\n",
    "        # Combine with the additional feature (e.g., stars)\n",
    "        combined_with_additional_feature = torch.cat((combined_features, stars), dim=1)\n",
    "\n",
    "        # Pass through the second hidden layer\n",
    "        classifier_hidden_output = self.dropout(\n",
    "            self.classifier_hidden_activation(\n",
    "                self.classifier_hidden(combined_with_additional_feature)\n",
    "            )\n",
    "        )\n",
    "\n",
    "        # Final classifier to get logits\n",
    "        logits = self.classifier(classifier_hidden_output)\n",
    "\n",
    "        return ModelOutput(logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>product</th>\n",
       "      <th>review</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Listening to this \"Hurt\" me!</td>\n",
       "      <td>November 8, 2007</td>\n",
       "      <td>MomKKC \"momkkc\"</td>\n",
       "      <td>The Sun Also Rises (Audio CD)</td>\n",
       "      <td>William Hurt cannot read.  At all.  The cadenc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40% price hike, hmm</td>\n",
       "      <td>April 15, 2010</td>\n",
       "      <td>M. Barnhart</td>\n",
       "      <td>Heineken BT06 BeerTender Tubes, Pack of 6 (Kit...</td>\n",
       "      <td>As another reviewer noted, these used to be 10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Don't Mess With the Lupine Trinity!!!</td>\n",
       "      <td>June 2, 2010</td>\n",
       "      <td>Jake &amp;#34;The Wolfman&amp;#34; Sanchez</td>\n",
       "      <td>The Mountain Three Wolf Moon Short Sleeve Tee ...</td>\n",
       "      <td>I've read several reviews from people who have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>IT'S A BLENDER!</td>\n",
       "      <td>June 17, 2010</td>\n",
       "      <td>S. Cashdollar</td>\n",
       "      <td>Margaritaville DM1000 Frozen Concoction Maker ...</td>\n",
       "      <td>If you pay $250 for this blender you need your...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Another movie to ignore....</td>\n",
       "      <td>April 24, 2010</td>\n",
       "      <td>Kody \"ParisHiltonFan\"</td>\n",
       "      <td>Valentine's Day (DVD)</td>\n",
       "      <td>A perfect date movie: you'll miss absolutely n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stars                                  title              date  \\\n",
       "0   1.0           Listening to this \"Hurt\" me!  November 8, 2007   \n",
       "1   1.0                    40% price hike, hmm    April 15, 2010   \n",
       "2   5.0  Don't Mess With the Lupine Trinity!!!      June 2, 2010   \n",
       "3   1.0                        IT'S A BLENDER!     June 17, 2010   \n",
       "4   1.0            Another movie to ignore....    April 24, 2010   \n",
       "\n",
       "                               author  \\\n",
       "0                     MomKKC \"momkkc\"   \n",
       "1                         M. Barnhart   \n",
       "2  Jake &#34;The Wolfman&#34; Sanchez   \n",
       "3                       S. Cashdollar   \n",
       "4               Kody \"ParisHiltonFan\"   \n",
       "\n",
       "                                             product  \\\n",
       "0                      The Sun Also Rises (Audio CD)   \n",
       "1  Heineken BT06 BeerTender Tubes, Pack of 6 (Kit...   \n",
       "2  The Mountain Three Wolf Moon Short Sleeve Tee ...   \n",
       "3  Margaritaville DM1000 Frozen Concoction Maker ...   \n",
       "4                              Valentine's Day (DVD)   \n",
       "\n",
       "                                              review  is_sarcastic  \n",
       "0  William Hurt cannot read.  At all.  The cadenc...             1  \n",
       "1  As another reviewer noted, these used to be 10...             1  \n",
       "2  I've read several reviews from people who have...             1  \n",
       "3  If you pay $250 for this blender you need your...             1  \n",
       "4  A perfect date movie: you'll miss absolutely n...             1  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "amz_combined_file_path = \"../datasets/amazon_combined.parquet\"\n",
    "amz_combined_df = pd.read_parquet(amz_combined_file_path)\n",
    "\n",
    "# Display the first few rows of the dataset for a quick overview\n",
    "amz_combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(stars           0\n",
       " title           0\n",
       " date            0\n",
       " author          0\n",
       " product         0\n",
       " review          0\n",
       " is_sarcastic    0\n",
       " dtype: int64,\n",
       " is_sarcastic\n",
       " 0    0.651515\n",
       " 1    0.348485\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning: removing special characters and escape sequences from the sentences\n",
    "amz_combined_df[\"review\"] = amz_combined_df[\"review\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "amz_combined_df[\"product\"] = amz_combined_df[\"product\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "amz_combined_df[\"author\"] = amz_combined_df[\"author\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "amz_combined_df[\"title\"] = amz_combined_df[\"title\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "\n",
    "# Checking for any null values in the dataset\n",
    "amz_combined_null_check = amz_combined_df.isnull().sum()\n",
    "\n",
    "# Checking the distribution of the 'is_sarcastic' column\n",
    "amz_combined_label_distribution = amz_combined_df[\"is_sarcastic\"].value_counts(\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "amz_combined_null_check, amz_combined_label_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 188, 189)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation, and testing sets\n",
    "amz_combined_train_data, amz_combined_test_data = train_test_split(\n",
    "    amz_combined_df,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=amz_combined_df[\"is_sarcastic\"],  # Use the labels for stratification\n",
    ")\n",
    "amz_combined_val_data, amz_combined_test_data = train_test_split(\n",
    "    amz_combined_test_data,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=amz_combined_test_data[\n",
    "        \"is_sarcastic\"\n",
    "    ],  # Use the labels for stratification\n",
    ")\n",
    "\n",
    "# Showing the size of each split\n",
    "amz_combined_train_size, amz_combined_val_size, amz_combined_test_size = (\n",
    "    len(amz_combined_train_data),\n",
    "    len(amz_combined_val_data),\n",
    "    len(amz_combined_test_data),\n",
    ")\n",
    "amz_combined_train_size, amz_combined_val_size, amz_combined_test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate the dataset class & data loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for DataLoader\n",
    "AMZ_COMBINED_MAX_LEN = 128 * 3\n",
    "AMZ_COMBINED_BATCH_SIZE = 16\n",
    "\n",
    "# Compute class weights inverse proportional to class frequencies\n",
    "class_sample_counts = amz_combined_train_data[\"is_sarcastic\"].value_counts()\n",
    "class_weights = 1.0 / class_sample_counts\n",
    "weights = amz_combined_train_data[\"is_sarcastic\"].map(class_weights)\n",
    "weights = weights.to_numpy()\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "\n",
    "# Instantiate the custom Dataset for Amazon product reviews\n",
    "amz_combined_train_dataset = SarcasticProductReviewDataset(\n",
    "    data=amz_combined_train_data,\n",
    "    tokenizer=bert_base_uncased_tokenizer,\n",
    "    max_len=AMZ_COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "amz_combined_val_dataset = SarcasticProductReviewDataset(\n",
    "    data=amz_combined_val_data,\n",
    "    tokenizer=bert_base_uncased_tokenizer,\n",
    "    max_len=AMZ_COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "amz_combined_test_dataset = SarcasticProductReviewDataset(\n",
    "    data=amz_combined_test_data,\n",
    "    tokenizer=bert_base_uncased_tokenizer,\n",
    "    max_len=AMZ_COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "# Create DataLoader instances for training, validation, and testing\n",
    "amz_combined_train_loader = DataLoader(\n",
    "    dataset=amz_combined_train_dataset,\n",
    "    batch_size=AMZ_COMBINED_BATCH_SIZE,\n",
    "    sampler=sampler,  # Use the WeightedRandomSampler instead of shuffle\n",
    ")\n",
    "\n",
    "amz_combined_val_loader = DataLoader(\n",
    "    dataset=amz_combined_val_dataset, batch_size=AMZ_COMBINED_BATCH_SIZE\n",
    ")\n",
    "\n",
    "amz_combined_test_loader = DataLoader(\n",
    "    dataset=amz_combined_test_dataset, batch_size=AMZ_COMBINED_BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate the model & then necessary objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remikalbe/.pyenv/versions/3.10.4/envs/iit_dl_project/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "AMZ_COMBINED_PRETRAINED_MODEL_NAME_OR_PATH = COMBINED_PRETRAINED_MODEL_NAME_OR_PATH\n",
    "AMZ_COMBINED_NUM_LABELS = COMBINED_NUM_LABELS\n",
    "AMZ_COMBINED_HIDDEN_DROPOUT_PROB = 0.45\n",
    "AMZ_COMBINED_ATTENTION_PROBS_DROPOUT_PROB = COMBINED_ATTENTION_PROBS_DROPOUT_PROB\n",
    "AMZ_COMBINED_NUM_EPOCHS = 3\n",
    "AMZ_COMBINED_LR = COMBINED_LR\n",
    "AMZ_COMBINED_WEIGHT_DECAY = 0.05\n",
    "\n",
    "# Specific hyperparameters for the amz model\n",
    "AMZ_COMBINED_HIDDEN_SIZE = 768  # Default hidden size for BERT base\n",
    "AMZ_COMBINED_STAR_HIDDEN_DROPOUT_PROB = 0.3  # Dropout rate for the star rating feature\n",
    "\n",
    "# Path to the fine-tuned BERT model\n",
    "FINE_TUNED_BERT_PATH = \"sarcastic_model.pth\"\n",
    "\n",
    "# Instantiate the extended model\n",
    "amz_combined_model = ExtendedBertForMultiFeatureClassification(\n",
    "    pretrained_bert_path=AMZ_COMBINED_PRETRAINED_MODEL_NAME_OR_PATH,\n",
    "    fine_tuned_bert_path=FINE_TUNED_BERT_PATH,\n",
    "    hidden_size=AMZ_COMBINED_HIDDEN_SIZE,\n",
    "    num_labels=AMZ_COMBINED_NUM_LABELS,\n",
    "    hidden_dropout_prob=AMZ_COMBINED_HIDDEN_DROPOUT_PROB,\n",
    "    attention_probs_dropout_prob=AMZ_COMBINED_ATTENTION_PROBS_DROPOUT_PROB,\n",
    "    classifier_dropout_prob=AMZ_COMBINED_STAR_HIDDEN_DROPOUT_PROB,\n",
    ")\n",
    "\n",
    "# Send the model to GPU if available\n",
    "amz_combined_model.to(device)  # type: ignore\n",
    "\n",
    "# Optimizer\n",
    "amz_combined_optimizer = AdamW(\n",
    "    amz_combined_model.parameters(),\n",
    "    lr=AMZ_COMBINED_LR,\n",
    "    weight_decay=AMZ_COMBINED_WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "# Total number of training steps\n",
    "amz_combined_total_steps = len(amz_combined_train_loader) * AMZ_COMBINED_NUM_EPOCHS\n",
    "\n",
    "# Scheduler for learning rate\n",
    "amz_combined_scheduler = get_linear_schedule_with_warmup(\n",
    "    amz_combined_optimizer,\n",
    "    num_warmup_steps=COMBINED_NUM_WARMUP_STEPS,\n",
    "    num_training_steps=amz_combined_total_steps,\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "amz_combined_loss_fn = CrossEntropyLoss()\n",
    "\n",
    "amz_combined_feature_keys = [\n",
    "    \"title_input_ids\",\n",
    "    \"title_attention_mask\",\n",
    "    \"author_input_ids\",\n",
    "    \"author_attention_mask\",\n",
    "    \"product_input_ids\",\n",
    "    \"product_attention_mask\",\n",
    "    \"review_input_ids\",\n",
    "    \"review_attention_mask\",\n",
    "    \"stars\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual training and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/55 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [02:59<00:00,  3.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics: accuracy: 0.6328 | precision_sarcasm: 0.6235 | recall_sarcasm: 0.6206 | precision_non_sarcasm: 0.9993 | recall_non_sarcasm: 0.9993 | loss: 0.6717\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:12<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: accuracy: 0.8085 | precision_sarcasm: 0.8718 | recall_sarcasm: 0.5231 | precision_non_sarcasm: 0.9994 | recall_non_sarcasm: 0.9999 | loss: 0.6268\n",
      "Saved Best Model!\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [02:50<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics: accuracy: 0.6796 | precision_sarcasm: 0.6928 | recall_sarcasm: 0.6943 | precision_non_sarcasm: 0.9994 | recall_non_sarcasm: 0.9994 | loss: 0.6533\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:10<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: accuracy: 0.8298 | precision_sarcasm: 0.8235 | recall_sarcasm: 0.6462 | precision_non_sarcasm: 0.9995 | recall_non_sarcasm: 0.9998 | loss: 0.6165\n",
      "Saved Best Model!\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [02:49<00:00,  3.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics: accuracy: 0.7571 | precision_sarcasm: 0.7783 | recall_sarcasm: 0.7423 | precision_non_sarcasm: 0.9995 | recall_non_sarcasm: 0.9996 | loss: 0.6303\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:11<00:00,  1.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: accuracy: 0.8245 | precision_sarcasm: 0.8077 | recall_sarcasm: 0.6462 | precision_non_sarcasm: 0.9995 | recall_non_sarcasm: 0.9998 | loss: 0.6131\n",
      "\n",
      "Best Validation Accuracy: 0.8298 on Epoch 2\n"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "train_and_evaluate(\n",
    "    model=amz_combined_model,\n",
    "    train_loader=amz_combined_train_loader,\n",
    "    val_loader=amz_combined_val_loader,\n",
    "    optimizer=amz_combined_optimizer,\n",
    "    scheduler=amz_combined_scheduler,\n",
    "    loss_fn=amz_combined_loss_fn,\n",
    "    device=device,\n",
    "    num_epochs=AMZ_COMBINED_NUM_EPOCHS,\n",
    "    train_dataset_len=len(amz_combined_train_dataset),\n",
    "    val_dataset_len=len(amz_combined_val_dataset),\n",
    "    feature_keys=amz_combined_feature_keys,\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "AMZ_FINE_TUNED_BERT_PATH = \"amazon_sarcastic_model.pth\"\n",
    "torch.save(amz_combined_model.state_dict(), AMZ_FINE_TUNED_BERT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
