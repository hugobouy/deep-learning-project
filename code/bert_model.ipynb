{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  is_sarcastic\n",
       "0  thirtysomething scientists unveil doomsday clo...           1.0\n",
       "1  dem rep. totally nails why congress is falling...           0.0\n",
       "2  eat your veggies: 9 deliciously different recipes           0.0\n",
       "3  inclement weather prevents liar from getting t...           1.0\n",
       "4  mother comes pretty close to using word 'strea...           1.0"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the dataset\n",
    "file_path = \"../datasets/combined.parquet\"\n",
    "data = pd.read_parquet(file_path)\n",
    "\n",
    "# Display the first few rows of the dataset for a quick overview\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sentence        0\n",
       " is_sarcastic    0\n",
       " dtype: int64,\n",
       " is_sarcastic\n",
       " 0.0    0.521391\n",
       " 1.0    0.478609\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any null values in the dataset\n",
    "null_check = data.isnull().sum()\n",
    "\n",
    "# Checking the distribution of the 'is_sarcastic' column\n",
    "label_distribution = data[\"is_sarcastic\"].value_counts(normalize=True)\n",
    "\n",
    "null_check, label_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28322, 6069, 6070)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Data cleaning: removing special characters and escape sequences from the sentences\n",
    "data[\"sentence\"] = data[\"sentence\"].apply(lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x))\n",
    "\n",
    "# Splitting the dataset into training, validation, and testing sets\n",
    "train_data, test_data = train_test_split(data, test_size=0.3, random_state=42)\n",
    "val_data, test_data = train_test_split(test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Showing the size of each split\n",
    "train_size, val_size, test_size = len(train_data), len(val_data), len(test_data)\n",
    "train_size, val_size, test_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': ['girlfriend to stay underneath blanket for next 5 months',\n",
       "  'is putting a plastic container in the microwave really that bad?',\n",
       "  \"jennifer lawrence may hate singing, but now she's a pop star\",\n",
       "  \"kim cattrall's missing brother found dead at his home\",\n",
       "  'advisors hopeful jeb bush finally has momentum to end campaign',\n",
       "  'Did you slip in it AGAIN? Were you led astray by a passage from Heller you thought you could use to legitimize gun control, your wet dream? I submit from many past rulings of the courts that little statement is in error.',\n",
       "  'goodyear unveils new, circular tires',\n",
       "  'Ah! So wellspoken for an addle-pated twiddle poop! I congratulate you! And a total lie! Who the Hades wants 13-year-old children to be sexually active? No responsible, thinking person could wish such a thing. You malign Planned Parenthood. You have ceased to be a credible commentator on this issue.',\n",
       "  'senate bill may answer a decades-old request',\n",
       "  \"so you are into pommy bashing now? mae honey, is there anybody you don't like? emoticonXRolleyes\",\n",
       "  'As \"special\" as being one of over 100Million makes me. emoticonXRolleyes',\n",
       "  \"johnson & johnson hoping brand won't be tarnished if they dip into lethal injection game\",\n",
       "  '8 crazy things that happen to your body when you have tons of sex',\n",
       "  'who urges end to routine antibiotic use in farm animals to stem rise of superbugs',\n",
       "  \"entertainment tonight host 'can't wait' to see new paramount pictures release\",\n",
       "  'If only there was something in your head to control the things you say.'],\n",
       " 'input_ids': tensor([[  101,  6513,  2000,  ...,     0,     0,     0],\n",
       "         [  101,  2003,  5128,  ...,     0,     0,     0],\n",
       "         [  101,  7673,  5623,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  2040, 23876,  ...,     0,     0,     0],\n",
       "         [  101,  4024,  3892,  ...,     0,     0,     0],\n",
       "         [  101,  2065,  2069,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1])}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "\n",
    "# Initialize the BERT tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "\n",
    "class SarcasticSentencesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset for the sarcastic sentences dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sentence = str(self.sentences[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        # Encoding the sentences using the tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",  # Return PyTorch tensors\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"sentence\": sentence,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "\n",
    "# Constants\n",
    "MAX_LEN = 128  # Maximum length of the tokens list\n",
    "BATCH_SIZE = 16\n",
    "\n",
    "# Creating instances of the SarcasticSentencesDataset\n",
    "train_dataset = SarcasticSentencesDataset(\n",
    "    train_data[\"sentence\"].to_numpy(),\n",
    "    train_data[\"is_sarcastic\"].to_numpy(),\n",
    "    tokenizer,\n",
    "    MAX_LEN,\n",
    ")\n",
    "\n",
    "val_dataset = SarcasticSentencesDataset(\n",
    "    val_data[\"sentence\"].to_numpy(),\n",
    "    val_data[\"is_sarcastic\"].to_numpy(),\n",
    "    tokenizer,\n",
    "    MAX_LEN,\n",
    ")\n",
    "\n",
    "test_dataset = SarcasticSentencesDataset(\n",
    "    test_data[\"sentence\"].to_numpy(),\n",
    "    test_data[\"is_sarcastic\"].to_numpy(),\n",
    "    tokenizer,\n",
    "    MAX_LEN,\n",
    ")\n",
    "\n",
    "# Creating the DataLoaders for training, validation, and testing\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Checking the first batch from the train_loader\n",
    "next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from tqdm import tqdm  # for displaying progress\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\n",
    "    \"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import Module, CrossEntropyLoss\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "def train_epoch(\n",
    "    model: Module,\n",
    "    data_loader: DataLoader,\n",
    "    optimizer: Optimizer,\n",
    "    device: torch.device,\n",
    "    scheduler: _LRScheduler,\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    n_examples: int,\n",
    ") -> Dict[str, float]:\n",
    "    model.train()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Initialize counters\n",
    "    tp_sarcasm = 0\n",
    "    tn_non_sarcasm = 0\n",
    "    fp_sarcasm = 0\n",
    "    fn_sarcasm = 0\n",
    "\n",
    "    for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "        input_ids = batch[\"input_ids\"].to(device)\n",
    "        attention_mask = batch[\"attention_mask\"].to(device)\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "        # Update TP, TN, FP, FN counters\n",
    "        tp_sarcasm += torch.sum((preds == 1) & (labels == 1)).item()\n",
    "        tn_non_sarcasm += torch.sum((preds == 0) & (labels == 0)).item()\n",
    "        fp_sarcasm += torch.sum((preds == 1) & (labels == 0)).item()\n",
    "        fn_sarcasm += torch.sum((preds == 0) & (labels == 1)).item()\n",
    "\n",
    "    # Compute precision and recall for sarcasm\n",
    "    precision_sarcasm = tp_sarcasm / (tp_sarcasm + fp_sarcasm + 1e-10)\n",
    "    recall_sarcasm = tp_sarcasm / (tp_sarcasm + fn_sarcasm + 1e-10)\n",
    "\n",
    "    # Compute precision and recall for non-sarcasm\n",
    "    precision_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fn_sarcasm + 1e-10)\n",
    "    recall_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fp_sarcasm + 1e-10)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_predictions.float() / n_examples,\n",
    "        \"precision_sarcasm\": precision_sarcasm,\n",
    "        \"recall_sarcasm\": recall_sarcasm,\n",
    "        \"precision_non_sarcasm\": precision_non_sarcasm,\n",
    "        \"recall_non_sarcasm\": recall_non_sarcasm,\n",
    "        \"loss\": np.mean(losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(\n",
    "    model: Module,\n",
    "    data_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    n_examples: int,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "    losses = []\n",
    "    correct_predictions = 0\n",
    "\n",
    "    # Initialize counters\n",
    "    tp_sarcasm = 0\n",
    "    tn_non_sarcasm = 0\n",
    "    fp_sarcasm = 0\n",
    "    fn_sarcasm = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "            input_ids = batch[\"input_ids\"].to(device)\n",
    "            attention_mask = batch[\"attention_mask\"].to(device)\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "            # Update TP, TN, FP, FN counters\n",
    "            tp_sarcasm += torch.sum((preds == 1) & (labels == 1)).item()\n",
    "            tn_non_sarcasm += torch.sum((preds == 0) & (labels == 0)).item()\n",
    "            fp_sarcasm += torch.sum((preds == 1) & (labels == 0)).item()\n",
    "            fn_sarcasm += torch.sum((preds == 0) & (labels == 1)).item()\n",
    "\n",
    "    # Compute precision and recall for sarcasm\n",
    "    precision_sarcasm = tp_sarcasm / (tp_sarcasm + fp_sarcasm + 1e-10)\n",
    "    recall_sarcasm = tp_sarcasm / (tp_sarcasm + fn_sarcasm + 1e-10)\n",
    "\n",
    "    # Compute precision and recall for non-sarcasm\n",
    "    precision_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fn_sarcasm + 1e-10)\n",
    "    recall_non_sarcasm = tn_non_sarcasm / (tn_non_sarcasm + fp_sarcasm + 1e-10)\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_predictions.float() / n_examples,\n",
    "        \"precision_sarcasm\": precision_sarcasm,\n",
    "        \"recall_sarcasm\": recall_sarcasm,\n",
    "        \"precision_non_sarcasm\": precision_non_sarcasm,\n",
    "        \"recall_non_sarcasm\": recall_non_sarcasm,\n",
    "        \"loss\": np.mean(losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/remikalbe/.pyenv/versions/3.10.4/envs/iit_dl_project/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [09:38<00:00,  3.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Loss: 0.3494 | Accuracy: 0.8383 | Sarcasm Precision: 0.8309 | Sarcasm Recall: 0.8312 | Non-Sarcasm Precision: 0.8450 | Non-Sarcasm Recall: 0.8448\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:40<00:00,  9.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Loss: 0.3157 | Accuracy: 0.8623 | Sarcasm Precision: 0.8939 | Sarcasm Recall: 0.8109 | Non-Sarcasm Precision: 0.8376 | Non-Sarcasm Recall: 0.9102\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [10:57<00:00,  2.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Loss: 0.1788 | Accuracy: 0.9248 | Sarcasm Precision: 0.9195 | Sarcasm Recall: 0.9237 | Non-Sarcasm Precision: 0.9297 | Non-Sarcasm Recall: 0.9258\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:42<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Loss: 0.3026 | Accuracy: 0.8845 | Sarcasm Precision: 0.8699 | Sarcasm Recall: 0.8945 | Non-Sarcasm Precision: 0.8989 | Non-Sarcasm Recall: 0.8751\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [11:44<00:00,  2.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Loss: 0.0818 | Accuracy: 0.9683 | Sarcasm Precision: 0.9643 | Sarcasm Recall: 0.9697 | Non-Sarcasm Precision: 0.9720 | Non-Sarcasm Recall: 0.9670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:41<00:00,  9.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Loss: 0.3940 | Accuracy: 0.8786 | Sarcasm Precision: 0.8963 | Sarcasm Recall: 0.8464 | Non-Sarcasm Precision: 0.8637 | Non-Sarcasm Recall: 0.9086\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained model\n",
    "model = BertForSequenceClassification.from_pretrained(\"bert-base-uncased\", num_labels=2)\n",
    "model.to(device)  # Send the model to GPU if available\n",
    "\n",
    "# Optimizer\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_epochs = 3\n",
    "\n",
    "# Total number of training steps\n",
    "total_steps = len(train_loader) * num_epochs\n",
    "\n",
    "# Scheduler for learning rate\n",
    "scheduler = get_linear_schedule_with_warmup(\n",
    "    optimizer, num_warmup_steps=0, num_training_steps=total_steps\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Training and Validation\n",
    "for epoch in range(num_epochs):\n",
    "    print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "    print(\"-\" * 10)\n",
    "\n",
    "    # Training phase\n",
    "    train_output = train_epoch(\n",
    "        model, train_loader, optimizer, device, scheduler, loss_fn, len(train_dataset)\n",
    "    )\n",
    "\n",
    "    print(f\"Training Metrics:\")\n",
    "    train_metrics = [\n",
    "        f\"Loss: {train_output['loss']:.4f}\",\n",
    "        f\"Accuracy: {train_output['accuracy']:.4f}\",\n",
    "        f\"Sarcasm Precision: {train_output['precision_sarcasm']:.4f}\",\n",
    "        f\"Sarcasm Recall: {train_output['recall_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Precision: {train_output['precision_non_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Recall: {train_output['recall_non_sarcasm']:.4f}\",\n",
    "    ]\n",
    "    print(\" | \".join(train_metrics))\n",
    "\n",
    "    # Validation phase\n",
    "    val_output = eval_model(model, val_loader, device, loss_fn, len(val_dataset))\n",
    "\n",
    "    print(f\"Validation Metrics:\")\n",
    "    val_metrics = [\n",
    "        f\"Loss: {val_output['loss']:.4f}\",\n",
    "        f\"Accuracy: {val_output['accuracy']:.4f}\",\n",
    "        f\"Sarcasm Precision: {val_output['precision_sarcasm']:.4f}\",\n",
    "        f\"Sarcasm Recall: {val_output['recall_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Precision: {val_output['precision_non_sarcasm']:.4f}\",\n",
    "        f\"Non-Sarcasm Recall: {val_output['recall_non_sarcasm']:.4f}\",\n",
    "    ]\n",
    "    print(\" | \".join(val_metrics))\n",
    "\n",
    "    print()\n",
    "\n",
    "# Save the model\n",
    "torch.save(model.state_dict(), \"sarcastic_model.pth\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
