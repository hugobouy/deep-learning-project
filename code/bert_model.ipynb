{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sarcasm detection with BERT\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fine tunning on a combination of datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>thirtysomething scientists unveil doomsday clo...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>dem rep. totally nails why congress is falling...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>eat your veggies: 9 deliciously different recipes</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>inclement weather prevents liar from getting t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mother comes pretty close to using word 'strea...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  is_sarcastic\n",
       "0  thirtysomething scientists unveil doomsday clo...           1.0\n",
       "1  dem rep. totally nails why congress is falling...           0.0\n",
       "2  eat your veggies: 9 deliciously different recipes           0.0\n",
       "3  inclement weather prevents liar from getting t...           1.0\n",
       "4  mother comes pretty close to using word 'strea...           1.0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "combined_df_file_path = \"../datasets/combined.parquet\"\n",
    "combined_df = pd.read_parquet(combined_df_file_path)\n",
    "\n",
    "# Display the first few rows of the dataset for a quick overview\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Some statistics and cleaning\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(sentence        0\n",
       " is_sarcastic    0\n",
       " dtype: int64,\n",
       " is_sarcastic\n",
       " 0.0    0.521391\n",
       " 1.0    0.478609\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any null values in the dataset\n",
    "combined_df_null_check = combined_df.isnull().sum()\n",
    "\n",
    "# Data cleaning: removing special characters and escape sequences from the sentences\n",
    "combined_df[\"sentence\"] = combined_df[\"sentence\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "\n",
    "# Checking the distribution of the 'is_sarcastic' column\n",
    "combined_df_label_distribution = combined_df[\"is_sarcastic\"].value_counts(\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "combined_df_null_check, combined_df_label_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Splitting the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(28322, 6069, 6070)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation, and testing sets\n",
    "combined_train_data, combined_test_data = train_test_split(\n",
    "    combined_df, test_size=0.3, random_state=42\n",
    ")\n",
    "combined_val_data, combined_test_data = train_test_split(\n",
    "    combined_test_data, test_size=0.5, random_state=42\n",
    ")\n",
    "\n",
    "# Showing the size of each split\n",
    "combined_train_size, combined_val_size, combined_test_size = (\n",
    "    len(combined_train_data),\n",
    "    len(combined_val_data),\n",
    "    len(combined_test_data),\n",
    ")\n",
    "combined_train_size, combined_val_size, combined_test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Dataset class for the BertTokenizer & PyTorch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remikalbe/.pyenv/versions/3.10.4/envs/iit_dl_project/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformers import BertTokenizer\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcasticSentencesDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A custom PyTorch Dataset for the sarcastic sentences dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, sentences, labels, tokenizer, max_len):\n",
    "        self.sentences = sentences\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.sentences)\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        sentence = str(self.sentences[item])\n",
    "        label = self.labels[item]\n",
    "\n",
    "        # Encoding the sentences using the tokenizer\n",
    "        encoding = self.tokenizer.encode_plus(\n",
    "            sentence,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",  # Return PyTorch tensors\n",
    "            truncation=True,\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"sentence\": sentence,\n",
    "            \"input_ids\": encoding[\"input_ids\"].flatten(),\n",
    "            \"attention_mask\": encoding[\"attention_mask\"].flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'sentence': [\"The meticulously preserved, unchanging 66 Books of the Bible aren't compelling?\",\n",
       "  \"And I'm sure you of all people know the mind of God... Please, you just take snippets of scripture, and twist it into well this is absolute. God loves gays and lesbians, but you fling god out as a way to justify your slander and bigotry.  \",\n",
       "  'exclusive: bet responds after coming under fire from journalists and publicists',\n",
       "  \"saving the world's last 3 northern white rhino\",\n",
       "  'allies: islamist motive for killing nemtsov is nonsense',\n",
       "  'laid-off zoologist goes on tranquilizing rampage',\n",
       "  'annoying man more annoying after skydiving',\n",
       "  'paris terror harms france, islam, and the world',\n",
       "  \"former patriots and chiefs tackle ryan o'callaghan comes out as gay\",\n",
       "  '\"Placeholder\" would honestly be a better name than Pied Piper.',\n",
       "  \"snapchat's snapcash: is peer-to-peer payment safe?\",\n",
       "  'grown man purchases 37th sailor moon figurine',\n",
       "  'why we should tip service workers generously',\n",
       "  'emoticonXFrazzledTalk about a fast and loose accusation.WHAT DID HE ACTUALLY SAY???Cause Harry Hay is well known for his gay rights work.If Jennings did find something about the guy inspiring, it was probably his gay rights work.If I said that I thought Martin Luther King Jr was inspiring, would you automatically associate my praise with extramarital affairs?This is just stupid!',\n",
       "  \"'bubble boy' finally comfortable in his own skin\",\n",
       "  'experts caution new car loses 90% of value as soon as you drive it off cliff'],\n",
       " 'input_ids': tensor([[  101,  1996,  2777,  ...,     0,     0,     0],\n",
       "         [  101,  1998,  1045,  ...,     0,     0,     0],\n",
       "         [  101,  7262,  1024,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  7861, 20214,  ...,     0,     0,     0],\n",
       "         [  101,  1005, 11957,  ...,     0,     0,     0],\n",
       "         [  101,  8519, 14046,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]]),\n",
       " 'labels': tensor([0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1])}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize the BERT tokenizer\n",
    "bert_base_uncased_tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
    "\n",
    "# Constants\n",
    "COMBINED_MAX_LEN = 128  # Maximum length of the tokens list\n",
    "COMBINED_BATCH_SIZE = 16\n",
    "\n",
    "# Creating instances of the SarcasticSentencesDataset\n",
    "combined_train_dataset = SarcasticSentencesDataset(\n",
    "    combined_train_data[\"sentence\"].to_numpy(),\n",
    "    combined_train_data[\"is_sarcastic\"].to_numpy(),\n",
    "    bert_base_uncased_tokenizer,\n",
    "    COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "combined_val_dataset = SarcasticSentencesDataset(\n",
    "    combined_val_data[\"sentence\"].to_numpy(),\n",
    "    combined_val_data[\"is_sarcastic\"].to_numpy(),\n",
    "    bert_base_uncased_tokenizer,\n",
    "    COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "combined_test_dataset = SarcasticSentencesDataset(\n",
    "    combined_test_data[\"sentence\"].to_numpy(),\n",
    "    combined_test_data[\"is_sarcastic\"].to_numpy(),\n",
    "    bert_base_uncased_tokenizer,\n",
    "    COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "# Creating the DataLoaders for training, validation, and testing\n",
    "combined_train_loader = DataLoader(\n",
    "    combined_train_dataset, batch_size=COMBINED_BATCH_SIZE, shuffle=True\n",
    ")\n",
    "combined_val_loader = DataLoader(combined_val_dataset, batch_size=COMBINED_BATCH_SIZE)\n",
    "combined_test_loader = DataLoader(combined_test_dataset, batch_size=COMBINED_BATCH_SIZE)\n",
    "\n",
    "# Checking the first batch from the train_loader\n",
    "next(iter(combined_train_loader))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the train and validation loops\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch imports\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss, Module\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.lr_scheduler import _LRScheduler, LambdaLR\n",
    "\n",
    "# Transformers imports\n",
    "from transformers import (\n",
    "    BertForSequenceClassification,\n",
    "    AdamW,\n",
    "    get_linear_schedule_with_warmup,\n",
    ")\n",
    "\n",
    "# Typing imports\n",
    "from typing import Dict, Optional, List, Union\n",
    "\n",
    "# Other libraries\n",
    "from tqdm import tqdm\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device: torch.device = torch.device(\n",
    "    device=\"cuda\"\n",
    "    if torch.cuda.is_available()\n",
    "    else \"mps\"\n",
    "    if torch.backends.mps.is_available()\n",
    "    else \"cpu\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(\n",
    "    model: Module,\n",
    "    data_loader: DataLoader,\n",
    "    optimizer: Optimizer,\n",
    "    device: torch.device,\n",
    "    scheduler: Union[_LRScheduler, LambdaLR],\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    n_examples: int,\n",
    "    feature_keys: Optional[List[str]] = None,  # List of keys if present\n",
    ") -> Dict[str, float]:\n",
    "    model.train()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = torch.Tensor([0]).to(device)\n",
    "\n",
    "    # For calculating precision and recall\n",
    "    tp_sarcasm = 0\n",
    "    tn_non_sarcasm = 0\n",
    "    fp_sarcasm = 0\n",
    "    fn_sarcasm = 0\n",
    "\n",
    "    for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "        # Process inputs for single/multiple features\n",
    "        inputs = (\n",
    "            {key: batch[key].to(device) for key in feature_keys}\n",
    "            if feature_keys\n",
    "            else {\n",
    "                \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "                \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "            }\n",
    "        )\n",
    "        labels = batch[\"labels\"].to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(**inputs)\n",
    "        logits = outputs.logits\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        losses.append(loss.item())\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        _, preds = torch.max(logits, dim=1)\n",
    "        correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "        # Update TP, TN, FP, FN counters\n",
    "        tp_sarcasm += (preds & labels).sum().item()\n",
    "        tn_non_sarcasm += ((~preds.byte()) & (~labels.byte())).sum().item()\n",
    "        fp_sarcasm += (preds & (~labels.byte())).sum().item()\n",
    "        fn_sarcasm += ((~preds.byte()) & labels).sum().item()\n",
    "\n",
    "    # Calculate precision and recall for sarcasm class\n",
    "    precision_sarcasm = (\n",
    "        tp_sarcasm / (tp_sarcasm + fp_sarcasm) if (tp_sarcasm + fp_sarcasm) > 0 else 0\n",
    "    )\n",
    "    recall_sarcasm = (\n",
    "        tp_sarcasm / (tp_sarcasm + fn_sarcasm) if (tp_sarcasm + fn_sarcasm) > 0 else 0\n",
    "    )\n",
    "\n",
    "    # Calculate precision and recall for non-sarcasm class\n",
    "    precision_non_sarcasm = (\n",
    "        tn_non_sarcasm / (tn_non_sarcasm + fn_sarcasm)\n",
    "        if (tn_non_sarcasm + fn_sarcasm) > 0\n",
    "        else 0\n",
    "    )\n",
    "    recall_non_sarcasm = (\n",
    "        tn_non_sarcasm / (tn_non_sarcasm + fp_sarcasm)\n",
    "        if (tn_non_sarcasm + fp_sarcasm) > 0\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_predictions.float().item() / n_examples,\n",
    "        \"precision_sarcasm\": precision_sarcasm,\n",
    "        \"recall_sarcasm\": recall_sarcasm,\n",
    "        \"precision_non_sarcasm\": precision_non_sarcasm,\n",
    "        \"recall_non_sarcasm\": recall_non_sarcasm,\n",
    "        \"loss\": np.mean(losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_model(\n",
    "    model: Module,\n",
    "    data_loader: DataLoader,\n",
    "    device: torch.device,\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    n_examples: int,\n",
    "    feature_keys: Optional[List[str]] = None,\n",
    ") -> Dict[str, float]:\n",
    "    model.eval()\n",
    "\n",
    "    losses = []\n",
    "    correct_predictions = torch.Tensor([0]).to(device)\n",
    "\n",
    "    # Initialize counters for precision and recall\n",
    "    tp_sarcasm = 0\n",
    "    tn_non_sarcasm = 0\n",
    "    fp_sarcasm = 0\n",
    "    fn_sarcasm = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data_loader, total=len(data_loader)):\n",
    "            # Process inputs for single/multiple features\n",
    "            inputs = (\n",
    "                {key: batch[key].to(device) for key in feature_keys}\n",
    "                if feature_keys\n",
    "                else {\n",
    "                    \"input_ids\": batch[\"input_ids\"].to(device),\n",
    "                    \"attention_mask\": batch[\"attention_mask\"].to(device),\n",
    "                }\n",
    "            )\n",
    "            labels = batch[\"labels\"].to(device)\n",
    "\n",
    "            outputs = model(**inputs)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "            losses.append(loss.item())\n",
    "\n",
    "            _, preds = torch.max(logits, dim=1)\n",
    "            correct_predictions += torch.sum(preds == labels)\n",
    "\n",
    "            # Update TP, TN, FP, FN counters for precision and recall calculations\n",
    "            tp_sarcasm += (preds & labels).sum().item()\n",
    "            tn_non_sarcasm += ((~preds.byte()) & (~labels.byte())).sum().item()\n",
    "            fp_sarcasm += (preds & (~labels.byte())).sum().item()\n",
    "            fn_sarcasm += ((~preds.byte()) & labels).sum().item()\n",
    "\n",
    "    # Calculate precision and recall for sarcasm class\n",
    "    precision_sarcasm = (\n",
    "        tp_sarcasm / (tp_sarcasm + fp_sarcasm) if (tp_sarcasm + fp_sarcasm) > 0 else 0\n",
    "    )\n",
    "    recall_sarcasm = (\n",
    "        tp_sarcasm / (tp_sarcasm + fn_sarcasm) if (tp_sarcasm + fn_sarcasm) > 0 else 0\n",
    "    )\n",
    "\n",
    "    # Calculate precision and recall for non-sarcasm class\n",
    "    precision_non_sarcasm = (\n",
    "        tn_non_sarcasm / (tn_non_sarcasm + fn_sarcasm)\n",
    "        if (tn_non_sarcasm + fn_sarcasm) > 0\n",
    "        else 0\n",
    "    )\n",
    "    recall_non_sarcasm = (\n",
    "        tn_non_sarcasm / (tn_non_sarcasm + fp_sarcasm)\n",
    "        if (tn_non_sarcasm + fp_sarcasm) > 0\n",
    "        else 0\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": correct_predictions.float().item() / n_examples,\n",
    "        \"precision_sarcasm\": precision_sarcasm,\n",
    "        \"recall_sarcasm\": recall_sarcasm,\n",
    "        \"precision_non_sarcasm\": precision_non_sarcasm,\n",
    "        \"recall_non_sarcasm\": recall_non_sarcasm,\n",
    "        \"loss\": np.mean(losses),\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training & evaluation of the model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the train and validation loop\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(\n",
    "    model: Module,\n",
    "    train_loader: DataLoader,\n",
    "    val_loader: DataLoader,\n",
    "    optimizer: Optimizer,\n",
    "    scheduler: Union[_LRScheduler, LambdaLR],\n",
    "    loss_fn: CrossEntropyLoss,\n",
    "    device: torch.device,\n",
    "    num_epochs: int,\n",
    "    train_dataset_len: int,\n",
    "    val_dataset_len: int,\n",
    "    feature_keys: Optional[List[str]] = None,\n",
    "):\n",
    "    best_accuracy = 0.0\n",
    "    best_epoch = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}\")\n",
    "        print(\"-\" * 10)\n",
    "\n",
    "        # Training phase\n",
    "        train_output = train_epoch(\n",
    "            model=model,\n",
    "            data_loader=train_loader,\n",
    "            optimizer=optimizer,\n",
    "            device=device,\n",
    "            scheduler=scheduler,\n",
    "            loss_fn=loss_fn,\n",
    "            n_examples=train_dataset_len,\n",
    "            feature_keys=feature_keys,\n",
    "        )\n",
    "\n",
    "        train_metrics_str = \" | \".join(\n",
    "            f\"{metric}: {value:.4f}\" for metric, value in train_output.items()\n",
    "        )\n",
    "        print(f\"Training Metrics: {train_metrics_str}\")\n",
    "\n",
    "        # Validation phase\n",
    "        val_output = eval_model(\n",
    "            model=model,\n",
    "            data_loader=val_loader,\n",
    "            device=device,\n",
    "            loss_fn=loss_fn,\n",
    "            n_examples=val_dataset_len,\n",
    "            feature_keys=feature_keys,\n",
    "        )\n",
    "\n",
    "        val_metrics_str = \" | \".join(\n",
    "            f\"{metric}: {value:.4f}\" for metric, value in val_output.items()\n",
    "        )\n",
    "        print(f\"Validation Metrics: {val_metrics_str}\")\n",
    "\n",
    "        # Example: Save the best model based on validation accuracy\n",
    "        if val_output[\"accuracy\"] > best_accuracy:\n",
    "            best_accuracy = val_output[\"accuracy\"]\n",
    "            best_epoch = epoch\n",
    "            torch.save(model.state_dict(), \"best_model.pth\")\n",
    "            print(\"Saved Best Model!\")\n",
    "\n",
    "        print()\n",
    "\n",
    "    print(f\"Best Validation Accuracy: {best_accuracy:.4f} on Epoch {best_epoch + 1}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Actual training and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "/Users/remikalbe/.pyenv/versions/3.10.4/envs/iit_dl_project/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [09:58<00:00,  2.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Loss: 0.4146 | Accuracy: 0.8031 | Sarcasm Precision: 0.7991 | Sarcasm Recall: 0.7860 | Non-Sarcasm Precision: 0.9996 | Non-Sarcasm Recall: 0.9996\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:40<00:00,  9.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Loss: 0.3539 | Accuracy: 0.8423 | Sarcasm Precision: 0.8892 | Sarcasm Recall: 0.7693 | Non-Sarcasm Precision: 0.9996 | Non-Sarcasm Recall: 0.9998\n",
      "\n",
      "Epoch 2/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [11:04<00:00,  2.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Loss: 0.2959 | Accuracy: 0.8718 | Sarcasm Precision: 0.8616 | Sarcasm Recall: 0.8721 | Non-Sarcasm Precision: 0.9998 | Non-Sarcasm Recall: 0.9997\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:35<00:00, 10.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Loss: 0.3605 | Accuracy: 0.8433 | Sarcasm Precision: 0.9149 | Sarcasm Recall: 0.7447 | Non-Sarcasm Precision: 0.9995 | Non-Sarcasm Recall: 0.9999\n",
      "\n",
      "Epoch 3/3\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1771/1771 [11:48<00:00,  2.50it/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics:\n",
      "Loss: 0.2452 | Accuracy: 0.8939 | Sarcasm Precision: 0.8832 | Sarcasm Recall: 0.8969 | Non-Sarcasm Precision: 0.9998 | Non-Sarcasm Recall: 0.9998\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 380/380 [00:29<00:00, 12.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics:\n",
      "Loss: 0.3809 | Accuracy: 0.8446 | Sarcasm Precision: 0.9183 | Sarcasm Recall: 0.7444 | Non-Sarcasm Precision: 0.9995 | Non-Sarcasm Recall: 0.9999\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "COMBINED_PRETRAINED_MODEL_NAME_OR_PATH = \"bert-base-uncased\"\n",
    "COMBINED_NUM_LABELS = 2  # Number of labels in the dataset\n",
    "COMBINED_HIDDEN_DROPOUT_PROB = 0.3  # Dropout rate\n",
    "COMBINED_ATTENTION_PROBS_DROPOUT_PROB = 0.3  # Dropout rate in attention heads\n",
    "COMBINED_NUM_EPOCHS = 3  # Number of epochs\n",
    "COMBINED_LR = 2e-5  # Learning rate\n",
    "COMBINED_WEIGHT_DECAY = 0.01  # Weight decay for regularization\n",
    "COMBINED_NUM_WARMUP_STEPS = 0  # Number of warmup steps for learning rate scheduler\n",
    "\n",
    "# Load pre-trained model\n",
    "combined_model = BertForSequenceClassification.from_pretrained(\n",
    "    pretrained_model_name_or_path=COMBINED_PRETRAINED_MODEL_NAME_OR_PATH,\n",
    "    num_labels=COMBINED_NUM_LABELS,\n",
    "    hidden_dropout_prob=COMBINED_HIDDEN_DROPOUT_PROB,  # dropout rate,\n",
    "    attention_probs_dropout_prob=COMBINED_ATTENTION_PROBS_DROPOUT_PROB,  # dropout rate in attention heads\n",
    ")\n",
    "\n",
    "# For typing purposes, check if model is an instance of Module\n",
    "if not isinstance(combined_model, Module):\n",
    "    raise ValueError(\"Model must be an instance of Module\")\n",
    "\n",
    "# Send the model to GPU if available\n",
    "combined_model.to(device=device)  # type: ignore\n",
    "\n",
    "# Optimizer\n",
    "combined_optimizer = AdamW(\n",
    "    combined_model.parameters(), lr=COMBINED_LR, weight_decay=COMBINED_WEIGHT_DECAY\n",
    ")\n",
    "\n",
    "# Total number of training steps\n",
    "combined_total_steps = len(combined_train_loader) * COMBINED_NUM_EPOCHS\n",
    "\n",
    "# Scheduler for learning rate\n",
    "combined_scheduler = get_linear_schedule_with_warmup(\n",
    "    combined_optimizer,\n",
    "    num_warmup_steps=COMBINED_NUM_WARMUP_STEPS,\n",
    "    num_training_steps=combined_total_steps,\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "combined_loss_fn = CrossEntropyLoss()\n",
    "\n",
    "# Feature keys\n",
    "combined_feature_keys = [\"input_ids\", \"attention_mask\"]\n",
    "\n",
    "# Train and evaluate the model\n",
    "train_and_evaluate(\n",
    "    model=combined_model,\n",
    "    train_loader=combined_train_loader,\n",
    "    val_loader=combined_val_loader,\n",
    "    optimizer=combined_optimizer,\n",
    "    scheduler=combined_scheduler,\n",
    "    loss_fn=combined_loss_fn,\n",
    "    device=device,\n",
    "    num_epochs=COMBINED_NUM_EPOCHS,\n",
    "    train_dataset_len=len(combined_train_dataset),\n",
    "    val_dataset_len=len(combined_val_dataset),\n",
    "    feature_keys=combined_feature_keys,\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "FINE_TUNED_BERT_PATH = \"sarcastic_model.pth\"\n",
    "torch.save(combined_model.state_dict(), FINE_TUNED_BERT_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a new model based on the pre-trained BERT model, adding review features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the dataset class for the new model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SarcasticProductReviewDataset(Dataset):\n",
    "    \"\"\"\n",
    "    A PyTorch Dataset class for sarcastic product reviews with multiple text features.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, data, tokenizer, max_len):\n",
    "        self.data = data\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        review_data = self.data.iloc[idx]\n",
    "        label = review_data[\"is_sarcastic\"]\n",
    "\n",
    "        # Tokenizing each text feature separately\n",
    "        title_encoding = self.tokenize_text_feature(review_data[\"title\"])\n",
    "        author_encoding = self.tokenize_text_feature(review_data[\"author\"])\n",
    "        product_encoding = self.tokenize_text_feature(review_data[\"product\"])\n",
    "        review_encoding = self.tokenize_text_feature(review_data[\"review\"])\n",
    "\n",
    "        # Convert stars rating to a tensor\n",
    "        stars_rating = torch.tensor([float(review_data[\"stars\"])], dtype=torch.float)\n",
    "\n",
    "        return {\n",
    "            \"title_input_ids\": title_encoding[\"input_ids\"].flatten(),\n",
    "            \"title_attention_mask\": title_encoding[\"attention_mask\"].flatten(),\n",
    "            \"author_input_ids\": author_encoding[\"input_ids\"].flatten(),\n",
    "            \"author_attention_mask\": author_encoding[\"attention_mask\"].flatten(),\n",
    "            \"product_input_ids\": product_encoding[\"input_ids\"].flatten(),\n",
    "            \"product_attention_mask\": product_encoding[\"attention_mask\"].flatten(),\n",
    "            \"review_input_ids\": review_encoding[\"input_ids\"].flatten(),\n",
    "            \"review_attention_mask\": review_encoding[\"attention_mask\"].flatten(),\n",
    "            \"stars\": stars_rating.flatten(),\n",
    "            \"labels\": torch.tensor(label, dtype=torch.long),\n",
    "        }\n",
    "\n",
    "    def tokenize_text_feature(self, text):\n",
    "        return self.tokenizer.encode_plus(\n",
    "            text,\n",
    "            add_special_tokens=True,  # Add '[CLS]' and '[SEP]'\n",
    "            max_length=self.max_len,  # truncate or pad to max_len\n",
    "            return_token_type_ids=False,\n",
    "            padding=\"max_length\",  # pad to max_length\n",
    "            return_attention_mask=True,\n",
    "            return_tensors=\"pt\",  # return tensors for PyTorch\n",
    "            truncation=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the model class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn import Linear, Dropout\n",
    "from transformers import BertModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ModelOutput:\n",
    "    def __init__(self, logits):\n",
    "        self.logits = logits\n",
    "\n",
    "\n",
    "class ExtendedBertForMultiFeatureClassification(Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        pretrained_bert_path,\n",
    "        fine_tuned_bert_path,\n",
    "        hidden_size,\n",
    "        num_labels,\n",
    "        hidden_dropout_prob,\n",
    "        attention_probs_dropout_prob,\n",
    "        star_hidden_dropout_prob,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        self.bert = BertModel.from_pretrained(\n",
    "            pretrained_model_name_or_path=pretrained_bert_path,\n",
    "            num_labels=num_labels,\n",
    "            hidden_dropout_prob=hidden_dropout_prob,  # dropout rate,\n",
    "            attention_probs_dropout_prob=attention_probs_dropout_prob,  # dropout rate in attention heads\n",
    "        )\n",
    "        if not isinstance(self.bert, Module):\n",
    "            raise ValueError(\"Model must be an instance of Module\")\n",
    "\n",
    "        # Load the state_dict from the saved model\n",
    "        state_dict = torch.load(fine_tuned_bert_path, map_location=torch.device(\"cpu\"))\n",
    "\n",
    "        # Remove the keys related to the classification head\n",
    "        state_dict = {\n",
    "            key: value\n",
    "            for key, value in state_dict.items()\n",
    "            if not key.startswith(\"classifier.\")\n",
    "        }\n",
    "\n",
    "        # Update the state with the weighed from the fine-tuned model (excluding classifier weights)\n",
    "        self.bert.load_state_dict(\n",
    "            state_dict, strict=False\n",
    "        )  # Set strict to False to ignore missing keys\n",
    "\n",
    "        # Assuming features for title, author, product, review\n",
    "        num_features = 4  # how many text features we're combining\n",
    "\n",
    "        # The feature combiner layer (you could have more complex architecture here if necessary)\n",
    "        self.feature_combiner = Linear(hidden_size * num_features, hidden_size)\n",
    "\n",
    "        # The classifier head\n",
    "        self.classifier = Linear(\n",
    "            hidden_size + 1, num_labels\n",
    "        )  # +1 for the star rating feature\n",
    "        self.dropout = Dropout(star_hidden_dropout_prob)\n",
    "\n",
    "    def forward(\n",
    "        self,\n",
    "        title_input_ids,\n",
    "        title_attention_mask,\n",
    "        author_input_ids,\n",
    "        author_attention_mask,\n",
    "        product_input_ids,\n",
    "        product_attention_mask,\n",
    "        review_input_ids,\n",
    "        review_attention_mask,\n",
    "        stars,\n",
    "    ):\n",
    "        if not isinstance(self.bert, Module):\n",
    "            raise ValueError(\"Model must be an instance of Module\")\n",
    "\n",
    "        # Process each text input through the fine-tuned BERT independently\n",
    "        # Extract the last hidden state of the [CLS] token from each output\n",
    "        title_cls = self.bert(\n",
    "            title_input_ids, attention_mask=title_attention_mask\n",
    "        ).pooler_output\n",
    "        author_cls = self.bert(\n",
    "            author_input_ids, attention_mask=author_attention_mask\n",
    "        ).pooler_output\n",
    "        product_cls = self.bert(\n",
    "            product_input_ids, attention_mask=product_attention_mask\n",
    "        ).pooler_output\n",
    "        review_cls = self.bert(\n",
    "            review_input_ids, attention_mask=review_attention_mask\n",
    "        ).pooler_output\n",
    "\n",
    "        # Combine [CLS] token outputs for all text features\n",
    "        combined_cls = torch.cat(\n",
    "            (\n",
    "                title_cls,  # Should be (batch_size, hidden_size)\n",
    "                author_cls,  # Should be (batch_size, hidden_size)\n",
    "                product_cls,  # Should be (batch_size, hidden_size)\n",
    "                review_cls,  # Should be (batch_size, hidden_size)\n",
    "            ),\n",
    "            dim=1,\n",
    "        )\n",
    "\n",
    "        # Make sure stars is 2D with shape (batch_size, 1)\n",
    "        stars = stars.unsqueeze(1) if stars.dim() == 1 else stars\n",
    "\n",
    "        # Apply dropout and pass through the combiner layer\n",
    "        combined_features = self.dropout(self.feature_combiner(combined_cls))\n",
    "\n",
    "        # Now combine the cls embeddings with the stars rating\n",
    "        combined_input = torch.cat((combined_features, stars), dim=1)\n",
    "\n",
    "        # Pass combined features through the final classifier layer\n",
    "        logits = self.classifier(combined_input)\n",
    "\n",
    "        return ModelOutput(logits=logits)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>stars</th>\n",
       "      <th>title</th>\n",
       "      <th>date</th>\n",
       "      <th>author</th>\n",
       "      <th>product</th>\n",
       "      <th>review</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Listening to this \"Hurt\" me!</td>\n",
       "      <td>November 8, 2007</td>\n",
       "      <td>MomKKC \"momkkc\"</td>\n",
       "      <td>The Sun Also Rises (Audio CD)</td>\n",
       "      <td>William Hurt cannot read.  At all.  The cadenc...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>40% price hike, hmm</td>\n",
       "      <td>April 15, 2010</td>\n",
       "      <td>M. Barnhart</td>\n",
       "      <td>Heineken BT06 BeerTender Tubes, Pack of 6 (Kit...</td>\n",
       "      <td>As another reviewer noted, these used to be 10...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "      <td>Don't Mess With the Lupine Trinity!!!</td>\n",
       "      <td>June 2, 2010</td>\n",
       "      <td>Jake &amp;#34;The Wolfman&amp;#34; Sanchez</td>\n",
       "      <td>The Mountain Three Wolf Moon Short Sleeve Tee ...</td>\n",
       "      <td>I've read several reviews from people who have...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>IT'S A BLENDER!</td>\n",
       "      <td>June 17, 2010</td>\n",
       "      <td>S. Cashdollar</td>\n",
       "      <td>Margaritaville DM1000 Frozen Concoction Maker ...</td>\n",
       "      <td>If you pay $250 for this blender you need your...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Another movie to ignore....</td>\n",
       "      <td>April 24, 2010</td>\n",
       "      <td>Kody \"ParisHiltonFan\"</td>\n",
       "      <td>Valentine's Day (DVD)</td>\n",
       "      <td>A perfect date movie: you'll miss absolutely n...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  stars                                  title              date  \\\n",
       "0   1.0           Listening to this \"Hurt\" me!  November 8, 2007   \n",
       "1   1.0                    40% price hike, hmm    April 15, 2010   \n",
       "2   5.0  Don't Mess With the Lupine Trinity!!!      June 2, 2010   \n",
       "3   1.0                        IT'S A BLENDER!     June 17, 2010   \n",
       "4   1.0            Another movie to ignore....    April 24, 2010   \n",
       "\n",
       "                               author  \\\n",
       "0                     MomKKC \"momkkc\"   \n",
       "1                         M. Barnhart   \n",
       "2  Jake &#34;The Wolfman&#34; Sanchez   \n",
       "3                       S. Cashdollar   \n",
       "4               Kody \"ParisHiltonFan\"   \n",
       "\n",
       "                                             product  \\\n",
       "0                      The Sun Also Rises (Audio CD)   \n",
       "1  Heineken BT06 BeerTender Tubes, Pack of 6 (Kit...   \n",
       "2  The Mountain Three Wolf Moon Short Sleeve Tee ...   \n",
       "3  Margaritaville DM1000 Frozen Concoction Maker ...   \n",
       "4                              Valentine's Day (DVD)   \n",
       "\n",
       "                                              review  is_sarcastic  \n",
       "0  William Hurt cannot read.  At all.  The cadenc...             1  \n",
       "1  As another reviewer noted, these used to be 10...             1  \n",
       "2  I've read several reviews from people who have...             1  \n",
       "3  If you pay $250 for this blender you need your...             1  \n",
       "4  A perfect date movie: you'll miss absolutely n...             1  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "amz_combined_file_path = \"../datasets/amazon_combined.parquet\"\n",
    "amz_combined_df = pd.read_parquet(amz_combined_file_path)\n",
    "\n",
    "# Display the first few rows of the dataset for a quick overview\n",
    "amz_combined_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(stars           0\n",
       " title           0\n",
       " date            0\n",
       " author          0\n",
       " product         0\n",
       " review          0\n",
       " is_sarcastic    0\n",
       " dtype: int64,\n",
       " is_sarcastic\n",
       " 0    0.651515\n",
       " 1    0.348485\n",
       " Name: proportion, dtype: float64)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data cleaning: removing special characters and escape sequences from the sentences\n",
    "amz_combined_df[\"review\"] = amz_combined_df[\"review\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "amz_combined_df[\"product\"] = amz_combined_df[\"product\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "amz_combined_df[\"author\"] = amz_combined_df[\"author\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "amz_combined_df[\"title\"] = amz_combined_df[\"title\"].apply(\n",
    "    lambda x: re.sub(r\"[\\n\\r\\t]+\", \" \", x)\n",
    ")\n",
    "\n",
    "# Checking for any null values in the dataset\n",
    "amz_combined_null_check = amz_combined_df.isnull().sum()\n",
    "\n",
    "# Checking the distribution of the 'is_sarcastic' column\n",
    "amz_combined_label_distribution = amz_combined_df[\"is_sarcastic\"].value_counts(\n",
    "    normalize=True\n",
    ")\n",
    "\n",
    "amz_combined_null_check, amz_combined_label_distribution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(877, 188, 189)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Splitting the dataset into training, validation, and testing sets\n",
    "amz_combined_train_data, amz_combined_test_data = train_test_split(\n",
    "    amz_combined_df,\n",
    "    test_size=0.3,\n",
    "    random_state=42,\n",
    "    stratify=amz_combined_df[\"is_sarcastic\"],  # Use the labels for stratification\n",
    ")\n",
    "amz_combined_val_data, amz_combined_test_data = train_test_split(\n",
    "    amz_combined_test_data,\n",
    "    test_size=0.5,\n",
    "    random_state=42,\n",
    "    stratify=amz_combined_test_data[\n",
    "        \"is_sarcastic\"\n",
    "    ],  # Use the labels for stratification\n",
    ")\n",
    "\n",
    "# Showing the size of each split\n",
    "amz_combined_train_size, amz_combined_val_size, amz_combined_test_size = (\n",
    "    len(amz_combined_train_data),\n",
    "    len(amz_combined_val_data),\n",
    "    len(amz_combined_test_data),\n",
    ")\n",
    "amz_combined_train_size, amz_combined_val_size, amz_combined_test_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate the dataset class & data loaders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import WeightedRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants for DataLoader\n",
    "AMZ_COMBINED_MAX_LEN = 128  # Maximum length of the tokens list\n",
    "AMZ_COMBINED_BATCH_SIZE = 16\n",
    "\n",
    "# Compute class weights inverse proportional to class frequencies\n",
    "class_sample_counts = amz_combined_train_data[\"is_sarcastic\"].value_counts()\n",
    "class_weights = 1.0 / class_sample_counts\n",
    "weights = amz_combined_train_data[\"is_sarcastic\"].map(class_weights)\n",
    "weights = weights.to_numpy()\n",
    "\n",
    "sampler = WeightedRandomSampler(weights, len(weights), replacement=True)\n",
    "\n",
    "# Instantiate the custom Dataset for Amazon product reviews\n",
    "amz_combined_train_dataset = SarcasticProductReviewDataset(\n",
    "    data=amz_combined_train_data,\n",
    "    tokenizer=bert_base_uncased_tokenizer,\n",
    "    max_len=AMZ_COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "amz_combined_val_dataset = SarcasticProductReviewDataset(\n",
    "    data=amz_combined_val_data,\n",
    "    tokenizer=bert_base_uncased_tokenizer,\n",
    "    max_len=AMZ_COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "amz_combined_test_dataset = SarcasticProductReviewDataset(\n",
    "    data=amz_combined_test_data,\n",
    "    tokenizer=bert_base_uncased_tokenizer,\n",
    "    max_len=AMZ_COMBINED_MAX_LEN,\n",
    ")\n",
    "\n",
    "# Create DataLoader instances for training, validation, and testing\n",
    "amz_combined_train_loader = DataLoader(\n",
    "    dataset=amz_combined_train_dataset,\n",
    "    batch_size=AMZ_COMBINED_BATCH_SIZE,\n",
    "    sampler=sampler,  # Use the WeightedRandomSampler instead of shuffle\n",
    ")\n",
    "\n",
    "amz_combined_val_loader = DataLoader(\n",
    "    dataset=amz_combined_val_dataset, batch_size=AMZ_COMBINED_BATCH_SIZE\n",
    ")\n",
    "\n",
    "amz_combined_test_loader = DataLoader(\n",
    "    dataset=amz_combined_test_dataset, batch_size=AMZ_COMBINED_BATCH_SIZE\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Instanciate the model & then necessary objects\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/remikalbe/.pyenv/versions/3.10.4/envs/iit_dl_project/lib/python3.10/site-packages/transformers/optimization.py:411: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Hyperparameters\n",
    "AMZ_COMBINED_PRETRAINED_MODEL_NAME_OR_PATH = COMBINED_PRETRAINED_MODEL_NAME_OR_PATH\n",
    "AMZ_COMBINED_NUM_LABELS = COMBINED_NUM_LABELS\n",
    "AMZ_COMBINED_HIDDEN_DROPOUT_PROB = COMBINED_HIDDEN_DROPOUT_PROB\n",
    "AMZ_COMBINED_ATTENTION_PROBS_DROPOUT_PROB = COMBINED_ATTENTION_PROBS_DROPOUT_PROB\n",
    "AMZ_COMBINED_NUM_EPOCHS = 10\n",
    "AMZ_COMBINED_LR = COMBINED_LR\n",
    "AMZ_COMBINED_WEIGHT_DECAY = COMBINED_WEIGHT_DECAY\n",
    "\n",
    "# Specific hyperparameters for the amz model\n",
    "AMZ_COMBINED_HIDDEN_SIZE = 768  # Default hidden size for BERT base\n",
    "AMZ_COMBINED_STAR_HIDDEN_DROPOUT_PROB = 0.3  # Dropout rate for the star rating feature\n",
    "\n",
    "# Path to the fine-tuned BERT model\n",
    "FINE_TUNED_BERT_PATH = \"sarcastic_model.pth\"\n",
    "\n",
    "# Instantiate the extended model\n",
    "amz_combined_model = ExtendedBertForMultiFeatureClassification(\n",
    "    pretrained_bert_path=AMZ_COMBINED_PRETRAINED_MODEL_NAME_OR_PATH,\n",
    "    fine_tuned_bert_path=FINE_TUNED_BERT_PATH,\n",
    "    hidden_size=AMZ_COMBINED_HIDDEN_SIZE,\n",
    "    num_labels=AMZ_COMBINED_NUM_LABELS,\n",
    "    hidden_dropout_prob=AMZ_COMBINED_HIDDEN_DROPOUT_PROB,\n",
    "    attention_probs_dropout_prob=AMZ_COMBINED_ATTENTION_PROBS_DROPOUT_PROB,\n",
    "    star_hidden_dropout_prob=AMZ_COMBINED_STAR_HIDDEN_DROPOUT_PROB,\n",
    ")\n",
    "\n",
    "# Send the model to GPU if available\n",
    "amz_combined_model.to(device)  # type: ignore\n",
    "\n",
    "# Optimizer\n",
    "amz_combined_optimizer = AdamW(\n",
    "    amz_combined_model.parameters(),\n",
    "    lr=AMZ_COMBINED_LR,\n",
    "    weight_decay=AMZ_COMBINED_WEIGHT_DECAY,\n",
    ")\n",
    "\n",
    "# Total number of training steps\n",
    "amz_combined_total_steps = len(amz_combined_train_loader) * AMZ_COMBINED_NUM_EPOCHS\n",
    "\n",
    "# Scheduler for learning rate\n",
    "amz_combined_scheduler = get_linear_schedule_with_warmup(\n",
    "    amz_combined_optimizer,\n",
    "    num_warmup_steps=COMBINED_NUM_WARMUP_STEPS,\n",
    "    num_training_steps=amz_combined_total_steps,\n",
    ")\n",
    "\n",
    "# Loss function\n",
    "amz_combined_loss_fn = CrossEntropyLoss()\n",
    "\n",
    "amz_combined_feature_keys = [\n",
    "    \"title_input_ids\",\n",
    "    \"title_attention_mask\",\n",
    "    \"author_input_ids\",\n",
    "    \"author_attention_mask\",\n",
    "    \"product_input_ids\",\n",
    "    \"product_attention_mask\",\n",
    "    \"review_input_ids\",\n",
    "    \"review_attention_mask\",\n",
    "    \"stars\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actual training and evaluation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 55/55 [00:56<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Metrics: accuracy: 0.5872 | precision_sarcasm: 0.5845 | recall_sarcasm: 0.6449 | precision_non_sarcasm: 0.9993 | recall_non_sarcasm: 0.9991 | loss: 0.6803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:03<00:00,  3.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation Metrics: accuracy: 0.7447 | precision_sarcasm: 0.8696 | recall_sarcasm: 0.3077 | precision_non_sarcasm: 0.9991 | recall_non_sarcasm: 0.9999 | loss: 0.5461\n",
      "Saved Best Model!\n",
      "\n",
      "Epoch 2/10\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 6/55 [00:06<00:49,  1.01s/it]"
     ]
    }
   ],
   "source": [
    "# Train and evaluate the model\n",
    "train_and_evaluate(\n",
    "    model=amz_combined_model,\n",
    "    train_loader=amz_combined_train_loader,\n",
    "    val_loader=amz_combined_val_loader,\n",
    "    optimizer=amz_combined_optimizer,\n",
    "    scheduler=amz_combined_scheduler,\n",
    "    loss_fn=amz_combined_loss_fn,\n",
    "    device=device,\n",
    "    num_epochs=AMZ_COMBINED_NUM_EPOCHS,\n",
    "    train_dataset_len=len(amz_combined_train_dataset),\n",
    "    val_dataset_len=len(amz_combined_val_dataset),\n",
    "    feature_keys=amz_combined_feature_keys,\n",
    ")\n",
    "\n",
    "# Save the model\n",
    "AMZ_FINE_TUNED_BERT_PATH = \"amazon_sarcastic_model.pth\"\n",
    "torch.save(amz_combined_model.state_dict(), AMZ_FINE_TUNED_BERT_PATH)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
